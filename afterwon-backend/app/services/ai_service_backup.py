import pandas as pd
import re
import httpx
import json
from openai import OpenAI
from typing import Dict, Any, List
from ..core.config import settings

class AIService:
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def analyze_data(self, df: pd.DataFrame, question: str, eda_data: Dict[str, Any] = None) -> Dict[str, Any]:
        print(f"ğŸš€ analyze_data called with question: '{question}'")
        """ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ ë° ì°¨íŠ¸ ì •ë³´ ë°˜í™˜"""
        
        # Provide comprehensive data analysis to AI - OPTIMIZED for large datasets
        if eda_data:
            data_info = self._format_eda_for_ai(eda_data)
            # Limit sample data to prevent token overflow
            preview_data = eda_data.get("preview", {}).get("head", df.head(3).to_dict())
            data_sample = str(preview_data)[:2000]  # Truncate long samples
        else:
            data_info = self._get_data_info(df)
            # Use smaller sample and truncate for large datasets
            sample_size = 3 if len(df) > 1000 else 5
            data_sample = str(df.head(sample_size).to_dict())[:2000]  # Truncate long samples
            
        # CRITICAL: Provide actual data statistics and aggregations to match chart generation
        data_statistics = self._get_comprehensive_data_stats(df, question)
        
        # ì‹¤ì œ ì»¬ëŸ¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        available_columns = df.columns.tolist()
        
        # Analyze user intent and map to appropriate columns
        intent_analysis = self._analyze_user_intent(question, available_columns)
        suggested_columns = intent_analysis['suggested_columns']
        analysis_focus = intent_analysis['analysis_focus']
        
        # OPTIMIZED analysis prompt - condensed for large datasets
        analysis_prompt = f"""
Data analyst task: Answer "{question}" using the dataset below.

DATASET: {len(df):,} records, {len(df.columns)} columns
KEY STATS: {data_statistics}
SAMPLE: {data_sample}
COLUMNS: {available_columns}

ANALYSIS FOCUS: {analysis_focus}
KEY COLUMNS: {suggested_columns}

CHART TYPE RULES (COMPREHENSIVE PLOTLY SUPPORT):
BASIC: "pie/line/bar/scatter/area" â†’ use respective type
STATISTICAL: "histogram/box/violin/strip/density_contour/density_heatmap/distplot/ecdf"
SPECIALIZED: "funnel/waterfall/treemap/sunburst/radar/heatmap"
GEO/MAP: "choropleth/scattergeo" â†’ for geographic data (countries, regions, coordinates)
3D: "scatter_3d/surface/line_3d/mesh3d"
FINANCIAL: "candlestick/ohlc"
MULTIVARIATE: "parallel_coordinates/parallel_categories"
KOREAN SUPPORT: íˆìŠ¤í† ê·¸ë¨/ë°•ìŠ¤í”Œë¡¯/ë°”ì´ì˜¬ë¦°/íŠ¸ë¦¬ë§µ/ì„ ë²„ìŠ¤íŠ¸/ë ˆì´ë”/íˆíŠ¸ë§µ/ê¹”ë•Œê¸°/í­í¬ì°¨íŠ¸/ì‚°í¬ë„/3Dì‚°ì ë„/í‘œë©´ì°¨íŠ¸/ìº”ë“¤ìŠ¤í‹±/í‰í–‰ì¢Œí‘œ/ë¶„í¬í”Œë¡¯/ëˆ„ì ë¶„í¬/ì§€ë„ì°¨íŠ¸/ì§€ë¦¬ì ì‚°ì ë„
GEOGRAPHIC KEYWORDS: ì§€ë„/ì§€ì—­/êµ­ê°€/ì‹œë„/ìœ„ì¹˜/ì¢Œí‘œ/latitude/longitude/country/region/map/ì§€ë„ì°¨íŠ¸ â†’ use "choropleth" or "scattergeo"
Default: proportionsâ†’pie, trendsâ†’line, comparisonsâ†’bar, correlationsâ†’scatter, distributionsâ†’histogram, hierarchicalâ†’treemap, financialâ†’candlestick, geographicâ†’choropleth

RESPONSE FORMAT (JSON only):
{{
  "insights": [
    "## í•µì‹¬ ë°œê²¬ì‚¬í•­\n- [í•µì‹¬ ë°œê²¬ì‚¬í•­ 1 - êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ]\n- [í•µì‹¬ ë°œê²¬ì‚¬í•­ 2 - ìˆ˜ì¹˜ì™€ í•¨ê»˜]\n- [í•µì‹¬ ë°œê²¬ì‚¬í•­ 3 - íŒ¨í„´ ì„¤ëª…]",
    "### ì£¼ìš” í†µê³„\n- ì „ì²´ ë°ì´í„° ìˆ˜: [ìˆ«ì]ê°œ\n- í•µì‹¬ ì§€í‘œ: [êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì„¤ëª…]\n- í‰ê· ê°’: [í‰ê· ]\n- ìµœëŒ“ê°’/ìµœì†Ÿê°’: [ë²”ìœ„ ì •ë³´]\n- ë¶„í¬ íŠ¹ì„±: [ë¶„í¬ì— ëŒ€í•œ ì„¤ëª…]",
    "### ì„¸ë¶€ ë¶„ì„\n- [íŒ¨í„´ 1]: [êµ¬ì²´ì  ì„¤ëª…ê³¼ ìˆ˜ì¹˜]\n- [íŒ¨í„´ 2]: [êµ¬ì²´ì  ì„¤ëª…ê³¼ ìˆ˜ì¹˜]\n- [íŠ¸ë Œë“œ]: [ì‹œê°„ë³„/ì¹´í…Œê³ ë¦¬ë³„ ë³€í™” ì–‘ìƒ]\n- [ìƒê´€ê´€ê³„]: [ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„ì™€ ê°•ë„]",
    "### ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸\n- [ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  1]: [êµ¬ì²´ì  ì˜ë¯¸ì™€ ì˜í–¥]\n- [ê°œì„ ë°©ì•ˆ]: [ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ]\n- [ë‹¤ìŒ ë¶„ì„ ë°©í–¥]: [ì¶”ê°€ ë¶„ì„ ì œì•ˆ]"
  ],
  "chart_type": "bar|line|pie|scatter|histogram|box|violin|treemap|sunburst|radar|heatmap|choropleth|scattergeo",
  "chart_columns": {{"x": "exact_column_name", "y": "exact_column_name"}},
  "summary": "{question}ì— ëŒ€í•œ ê°„ë‹¨ëª…ë£Œí•œ ë‹µë³€. ì¸ì‚¬ì´íŠ¸ì™€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ì§ì ‘ì ì¸ ë‹µë³€ë§Œ ì œê³µ.",
  "follow_up_questions": [
    "Follow-up question 1",
    "Follow-up question 2", 
    "Follow-up question 3"
  ]
}}
"""
        
        try:
            # Check if API key is properly set
            if not settings.OPENAI_API_KEY or settings.OPENAI_API_KEY == "your_openai_api_key_here":
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            response = self.client.chat.completions.create(
                model="gpt-4o",  # Use more powerful model for complex analysis
                messages=[
                    {"role": "system", "content": "You are a senior data analyst. Provide two distinct types of content: 1) 'summary': A brief, direct answer to the user's question (2-3 sentences max, no bullet points, no markdown headers). 2) 'insights': Detailed analysis using markdown headings (## ###) and bullet points (-) with specific findings, statistics, and recommendations. For mathematical expressions, use LaTeX notation enclosed in $ for inline math (like $\\frac{a}{b}$) or $$ for display math (like $$\\frac{numerator}{denominator}$$). Use proper LaTeX for fractions, square roots, exponents, etc. Ensure NO overlap between summary and insights content. Keep insights concise but comprehensive. Always complete your response - never truncate content."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.1,
                max_tokens=4000  # Allow more comprehensive responses without truncation
            )
            
            # JSON ì‘ë‹µ íŒŒì‹±
            raw_content = response.choices[0].message.content
            
            try:
                result = json.loads(raw_content)
                print(f"ğŸ“ JSON parsed result chart_type: {result.get('chart_type', 'N/A')}")
                # Ensure backward compatibility with old structure
                if "insights" not in result and "data_quality" in result:
                    # Convert new structure to backward compatible format
                    converted = self._convert_comprehensive_analysis(result)
                    print(f"ğŸ“ Converted result chart_type: {converted.get('chart_type', 'N/A')}")
                    return converted
                print(f"ğŸ“ Returning direct result with chart_type: {result.get('chart_type', 'N/A')}")

                # Use OpenAI's results as-is (no modifications)
                print(f"ğŸ”§ Using OpenAI results as-is:")
                print(f"   Chart Type: {result.get('chart_type')}")
                print(f"   Chart Columns: {result.get('chart_columns')}")
                print(f"   Insights: {len(result.get('insights', []))} items")

                return result
            except json.JSONDecodeError:
                # If JSON parsing fails, try to extract JSON from the content
                result = self._extract_json_from_response(raw_content)
                if result:
                    return result
                # If no JSON found, create conversational response
                return self._create_conversational_analysis(df, question, raw_content)
            
        except Exception as e:
            # ë” êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ
            error_msg = str(e)
            if "API key" in error_msg.lower() or "authentication" in error_msg.lower():
                insights = [
                    f"ë°ì´í„°ì— {len(df)} ê°œì˜ í–‰ê³¼ {len(df.columns)} ê°œì˜ ì—´ì´ ìˆìŠµë‹ˆë‹¤.",
                    "âš ï¸ OpenAI API í‚¤ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.",
                    "í˜„ì¬ëŠ” ê¸°ë³¸ í†µê³„ ì •ë³´ë§Œ ì œê³µí•©ë‹ˆë‹¤."
                ]
                summary = "OpenAI API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            else:
                insights = [
                    f"ë°ì´í„°ì— {len(df)} ê°œì˜ í–‰ê³¼ {len(df.columns)} ê°œì˜ ì—´ì´ ìˆìŠµë‹ˆë‹¤.",
                    f"ì˜¤ë¥˜ ë°œìƒ: {error_msg}",
                    "ê¸°ë³¸ ë°ì´í„° ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                ]
                summary = f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {error_msg}"
            
            # Use intent analysis for smart column selection in error cases too
            intent_analysis = self._analyze_user_intent(question, df.columns.tolist())
            x_col = intent_analysis['suggested_columns']['x']
            y_col = intent_analysis['suggested_columns']['y']
            
            # Generate follow-up questions even in error cases
            follow_up_questions = self._generate_follow_up_questions(question, df.columns.tolist(), intent_analysis)
            
            return {
                "insights": insights,
                "chart_type": intent_analysis['chart_type'],
                "chart_columns": {"x": x_col, "y": y_col},
                "summary": summary,
                "follow_up_questions": follow_up_questions
            }
    
    def _get_data_info(self, df: pd.DataFrame) -> str:
        """ë°ì´í„° ê¸°ë³¸ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        info = []
        info.append(f"í–‰ ìˆ˜: {len(df)}")
        info.append(f"ì—´ ìˆ˜: {len(df.columns)}")
        info.append(f"ì»¬ëŸ¼ëª…: {', '.join(df.columns.tolist())}")
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            info.append(f"ìˆ«ìí˜• ì»¬ëŸ¼: {', '.join(numeric_cols.tolist())}")
        
        return "; ".join(info)
    
    def _format_eda_for_ai(self, eda_data: Dict[str, Any]) -> str:
        """EDA ê²°ê³¼ë¥¼ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        info = []
        
        # ê¸°ë³¸ ì •ë³´
        basic = eda_data.get("basic_info", {})
        if basic:
            info.append(f"ë°ì´í„° í¬ê¸°: {basic.get('shape', 'N/A')}")
            info.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {basic.get('memory_usage', 'N/A')}")
        
        # ì»¬ëŸ¼ íƒ€ì… ì •ë³´
        col_types = eda_data.get("column_types", {})
        if col_types:
            info.append(f"ìˆ«ìí˜• ì»¬ëŸ¼ {col_types.get('numeric_count', 0)}ê°œ: {', '.join(col_types.get('numeric', []))}")
            info.append(f"ë²”ì£¼í˜• ì»¬ëŸ¼ {col_types.get('categorical_count', 0)}ê°œ: {', '.join(col_types.get('categorical', []))}")
            if col_types.get('datetime_count', 0) > 0:
                info.append(f"ë‚ ì§œí˜• ì»¬ëŸ¼ {col_types.get('datetime_count', 0)}ê°œ")
        
        # ë°ì´í„° í’ˆì§ˆ ì •ë³´
        quality = eda_data.get("data_quality", {})
        if quality:
            info.append(f"ë°ì´í„° ì™„ì„±ë„: {quality.get('completeness', 0)}%")
            info.append(f"ë°ì´í„° ê³ ìœ ì„±: {quality.get('uniqueness', 0)}%")
        
        # ê²°ì¸¡ê°’ ì •ë³´
        missing = eda_data.get("missing_data", {})
        if missing.get("total_missing", 0) > 0:
            info.append(f"ê²°ì¸¡ê°’: {missing.get('total_missing', 0)}ê°œ")
            missing_cols = list(missing.get("missing_by_column", {}).keys())
            if missing_cols:
                info.append(f"ê²°ì¸¡ê°’ ìˆëŠ” ì»¬ëŸ¼: {', '.join(missing_cols[:3])}")
        
        # ì¤‘ë³µ ë°ì´í„° ì •ë³´
        duplicates = eda_data.get("duplicates", {})
        if duplicates.get("duplicate_rows", 0) > 0:
            info.append(f"ì¤‘ë³µ í–‰: {duplicates.get('duplicate_rows', 0)}ê°œ ({duplicates.get('duplicate_percentage', 0)}%)")
        
        # ì¶”ì²œì‚¬í•­
        recommendations = eda_data.get("recommendations", [])
        if recommendations:
            info.append(f"ì¶”ì²œ ë¶„ì„: {', '.join(recommendations[:3])}")
        
        return "; ".join(info)
    
    def _get_comprehensive_data_stats(self, df: pd.DataFrame, question: str) -> str:
        """Generate OPTIMIZED data statistics that match what charts will show - REDUCED for large datasets"""
        stats = []
        
        # Get basic info
        stats.append(f"Total records: {len(df):,}")
        stats.append(f"Total columns: {len(df.columns)}")
        
        # OPTIMIZATION: Limit processing for large datasets to avoid token limits
        max_categorical_cols = 3  # Limit categorical analysis to prevent token overflow
        max_numeric_cols = 5      # Limit numeric analysis
        max_categories_per_col = 5  # Limit categories shown per column
        
        # Analyze categorical columns with value counts (what pie/bar charts will show)
        categorical_columns = df.select_dtypes(include=['object', 'category']).columns[:max_categorical_cols]
        
        for col in categorical_columns:
            if df[col].nunique() <= 50:  # Only for manageable categories, increased limit
                value_counts = df[col].value_counts()
                percentages = (df[col].value_counts(normalize=True) * 100).round(2)
                
                stats.append(f"\n{col} distribution (top {max_categories_per_col}):")
                for value, count in value_counts.head(max_categories_per_col).items():
                    percentage = percentages[value]
                    stats.append(f"  - {value}: {count:,} ({percentage}%)")
                    
                # Add summary for remaining categories if any
                if len(value_counts) > max_categories_per_col:
                    remaining = len(value_counts) - max_categories_per_col
                    stats.append(f"  - ... and {remaining} other categories")
        
        # Analyze numeric columns with basic statistics - LIMITED
        numeric_columns = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns[:max_numeric_cols]
        
        for col in numeric_columns:
            if not df[col].isna().all():
                stats.append(f"\n{col} stats: Mean={df[col].mean():.2f}, Min={df[col].min()}, Max={df[col].max()}, Count={df[col].count():,}")
        
        # Skip correlations for very large datasets to save tokens
        if len(df) < 5000 and len(numeric_columns) >= 2:
            try:
                corr_matrix = df[numeric_columns].corr()
                stats.append(f"\nKey correlations:")
                # Get strongest correlations - limit to top 3
                correlations = []
                for i in range(len(numeric_columns)):
                    for j in range(i+1, len(numeric_columns)):
                        corr_val = corr_matrix.iloc[i, j]
                        if abs(corr_val) > 0.3:  # Only significant correlations
                            correlations.append((abs(corr_val), f"{numeric_columns[i]} vs {numeric_columns[j]}: {corr_val:.3f}"))
                
                # Sort by strength and take top 3
                correlations.sort(reverse=True)
                for _, corr_text in correlations[:3]:
                    stats.append(f"  - {corr_text}")
            except:
                pass  # Skip if correlation fails
        
        # OPTIMIZED: Limit question-specific analysis to prevent token overflow
        question_lower = question.lower()
        question_matches = 0
        max_question_matches = 2  # Limit to 2 question-specific matches
        
        for col in df.columns[:5]:  # Only check first 5 columns
            if question_matches >= max_question_matches:
                break
                
            col_values = df[col].astype(str).str.lower()
            for word in question_lower.split()[:3]:  # Only check first 3 words
                if question_matches >= max_question_matches:
                    break
                    
                if len(word) > 2 and word in col_values.values:
                    matching_count = (col_values == word).sum()
                    total_count = len(df)
                    percentage = (matching_count / total_count * 100)
                    stats.append(f"\n'{word}' in {col}: {matching_count:,} ({percentage:.2f}%)")
                    question_matches += 1
        
        result = "; ".join(stats)
        
        # FINAL SAFEGUARD: Truncate if still too long
        if len(result) > 8000:  # Approximately 2000 tokens
            result = result[:8000] + "... (truncated for token limit)"
            
        return result
    
    def _generate_follow_up_questions(self, question: str, available_columns: List[str], intent_analysis: Dict[str, Any]) -> List[str]:
        """Generate contextual follow-up questions based on current analysis"""
        follow_ups = []
        question_lower = question.lower()
        
        # Get column types for smarter suggestions
        categorical_suggestions = []
        numeric_suggestions = []
        
        for col in available_columns:
            # Guess column types based on names (simple heuristic)
            col_lower = col.lower()
            if any(term in col_lower for term in ['country', 'region', 'type', 'category', 'status', 'method']):
                categorical_suggestions.append(col)
            elif any(term in col_lower for term in ['amount', 'value', 'price', 'count', 'number', 'rate']):
                numeric_suggestions.append(col)
        
        # Chart type specific follow-ups
        chart_type = intent_analysis.get('chart_type', 'bar')
        
        if chart_type == 'pie':
            # For pie charts, suggest comparisons and drill-downs
            follow_ups.extend([
                f"ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë³„ë¡œë„ ë¶„ì„í•´ì£¼ì„¸ìš”",
                f"ì´ ë°ì´í„°ë¥¼ ë§‰ëŒ€ ì°¨íŠ¸ë¡œë„ ë³´ì—¬ì£¼ì„¸ìš”",
                f"ìƒìœ„ 5ê°œ í•­ëª©ë§Œ ë”°ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”"
            ])
        elif chart_type == 'bar':
            # For bar charts, suggest trends and correlations
            follow_ups.extend([
                f"ì´ ë°ì´í„°ì˜ íŠ¸ë Œë“œë¥¼ ì„  ê·¸ë˜í”„ë¡œ ë³´ì—¬ì£¼ì„¸ìš”",
                f"ë¹„ìœ¨ë¡œ íŒŒì´ ì°¨íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
                f"í‰ê· ê°’ê³¼ ë¹„êµí•´ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”"
            ])
        elif chart_type == 'line':
            # For line charts, suggest correlations and predictions
            follow_ups.extend([
                f"ì´ íŠ¸ë Œë“œì˜ ì›ì¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
                f"ë‹¤ë¥¸ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”",
                f"ê³„ì ˆì„± íŒ¨í„´ì´ ìˆëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”"
            ])
        elif chart_type == 'scatter':
            # For scatter plots, suggest deeper correlations
            follow_ups.extend([
                f"ìƒê´€ê´€ê³„ì˜ ê°•ë„ë¥¼ ìˆ˜ì¹˜ë¡œ ë³´ì—¬ì£¼ì„¸ìš”",
                f"ì´ìƒì¹˜(outlier)ë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”",
                f"íšŒê·€ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”"
            ])
        
        # Content-based follow-ups
        if any(term in question_lower for term in ['country', 'êµ­ê°€', 'region']):
            follow_ups.append("ì§€ì—­ë³„ ì„±ê³¼ë¥¼ ì‹œê°„ì— ë”°ë¼ ë¶„ì„í•´ì£¼ì„¸ìš”")
            follow_ups.append("ê°€ì¥ ì„±ê³¼ê°€ ì¢‹ì€/ë‚˜ìœ ì§€ì—­ì€ ì–´ë””ì¸ê°€ìš”?")
        
        if any(term in question_lower for term in ['ì‹¤íŒ¨', 'fail', 'error', 'problem']):
            follow_ups.append("ì‹¤íŒ¨ ì›ì¸ë³„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”")
            follow_ups.append("ì‹¤íŒ¨ìœ¨ì´ ë†’ì€ ì‹œê°„ëŒ€ëŠ” ì–¸ì œì¸ê°€ìš”?")
        
        if any(term in question_lower for term in ['ë§¤ì¶œ', 'revenue', 'sales', 'amount']):
            follow_ups.append("ì›”ë³„ ë§¤ì¶œ ì„±ì¥ë¥ ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”")
            follow_ups.append("ë§¤ì¶œ êµ¬ê°„ë³„ ê³ ê° ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”")
        
        # Column-specific suggestions
        if categorical_suggestions:
            follow_ups.append(f"{categorical_suggestions[0]} ë³„ ìƒì„¸ ë¶„ì„ì„ í•´ì£¼ì„¸ìš”")
        
        if numeric_suggestions:
            follow_ups.append(f"{numeric_suggestions[0]}ì˜ í†µê³„ì  ë¶„í¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”")
        
        # General analytical follow-ups
        follow_ups.extend([
            "ì´ ê²°ê³¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ì–´ë–¤ ì•¡ì…˜ì„ ì·¨í•´ì•¼ í• ê¹Œìš”?",
            "ì´ìƒ íŒ¨í„´ì´ë‚˜ íŠ¹ì´ì‚¬í•­ì´ ìˆë‚˜ìš”?"
        ])
        
        # Remove duplicates and limit to 4 questions
        unique_follow_ups = list(dict.fromkeys(follow_ups))  # Preserves order while removing duplicates
        return unique_follow_ups[:4]
    
    def _analyze_user_intent(self, question: str, available_columns: List[str]) -> Dict[str, Any]:
        """Advanced context-aware intent analysis with deep semantic understanding"""
        question_lower = question.lower()
        
        # Enhanced semantic mappings with business context
        semantic_mappings = {
            # Payment/Transaction failures
            'failure': ['failure', 'error', 'fail', 'failed', 'failing', 'problem', 'issue', 'decline', 'declined', 'reject', 'rejected'],
            'success': ['success', 'successful', 'complete', 'completed', 'approved', 'passed', 'accept', 'accepted'],
            'reason': ['reason', 'message', 'cause', 'why', 'explanation', 'details', 'description', 'info'],
            'code': ['code', 'status_code', 'error_code', 'response_code', 'result_code'],
            
            # Card/Payment methods
            'card': ['card', 'payment_method', 'payment', 'credit', 'debit', 'visa', 'mastercard', 'amex', 'discover'],
            'network': ['network', 'type', 'brand', 'issuer', 'provider', 'company'],
            'country': ['country', 'location', 'region', 'nation', 'geography', 'address', 'origin'],
            
            # Customer/User analysis
            'customer': ['customer', 'user', 'client', 'account', 'holder', 'person', 'individual'],
            'order': ['order', 'transaction', 'purchase', 'payment', 'sale', 'attempt'],
            
            # Time/Temporal analysis
            'time': ['time', 'date', 'when', 'timestamp', 'created', 'updated', 'period', 'day', 'month'],
            'trend': ['trend', 'over_time', 'temporal', 'timeline', 'history', 'pattern', 'change'],
            
            # Quantity/Metrics
            'count': ['count', 'number', 'amount', 'quantity', 'total', 'sum', 'volume', 'frequency'],
            'rate': ['rate', 'percentage', 'ratio', 'proportion', 'percent', '%'],
            'value': ['value', 'amount', 'price', 'cost', 'fee', 'charge', 'money']
        }
        
        # Dynamic column mapping based on actual data and semantic understanding
        column_mappings = self._build_dynamic_column_mapping(available_columns, semantic_mappings)
        
        # Enhanced intent patterns with business context
        intent_patterns = {
            # Explicit chart type requests (highest priority)
            'pie chart': {'type': 'explicit_chart', 'chart': 'pie', 'focus': 'show proportional distribution as pie chart'},
            'pie': {'type': 'explicit_chart', 'chart': 'pie', 'focus': 'show proportional distribution as pie chart'},
            'íŒŒì´ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'pie', 'focus': 'show proportional distribution as pie chart'},
            'íŒŒì´ ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'pie', 'focus': 'show proportional distribution as pie chart'},
            'bar chart': {'type': 'explicit_chart', 'chart': 'bar', 'focus': 'show comparative distribution as bar chart'},
            'bar': {'type': 'explicit_chart', 'chart': 'bar', 'focus': 'show comparative distribution as bar chart'},
            'ë§‰ëŒ€ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'bar', 'focus': 'show comparative distribution as bar chart'},
            'ë§‰ëŒ€ ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'bar', 'focus': 'show comparative distribution as bar chart'},
            'line chart': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'line': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'ì„ ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'ì„  ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'ì„ ê·¸ë˜í”„': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'ì„  ê·¸ë˜í”„': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'ë¼ì¸ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'ë¼ì¸ ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'line', 'focus': 'show temporal trends as line chart'},
            'scatter plot': {'type': 'explicit_chart', 'chart': 'scatter', 'focus': 'show correlation as scatter plot'},
            'scatterplot': {'type': 'explicit_chart', 'chart': 'scatter', 'focus': 'show correlation as scatter plot'},
            'scatter': {'type': 'explicit_chart', 'chart': 'scatter', 'focus': 'show correlation as scatter plot'},
            'ì‚°í¬ë„': {'type': 'explicit_chart', 'chart': 'scatter', 'focus': 'show correlation as scatter plot'},
            'ì‚°ì ë„': {'type': 'explicit_chart', 'chart': 'scatter', 'focus': 'show correlation as scatter plot'},
            'histogram': {'type': 'explicit_chart', 'chart': 'histogram', 'focus': 'show data distribution as histogram'},
            'íˆìŠ¤í† ê·¸ë¨': {'type': 'explicit_chart', 'chart': 'histogram', 'focus': 'show data distribution as histogram'},
            'box plot': {'type': 'explicit_chart', 'chart': 'box', 'focus': 'show statistical distribution as box plot'},
            'boxplot': {'type': 'explicit_chart', 'chart': 'box', 'focus': 'show statistical distribution as box plot'},
            'ë°•ìŠ¤í”Œë¡¯': {'type': 'explicit_chart', 'chart': 'box', 'focus': 'show statistical distribution as box plot'},
            'ìƒìê·¸ë¦¼': {'type': 'explicit_chart', 'chart': 'box', 'focus': 'show statistical distribution as box plot'},
            'area chart': {'type': 'explicit_chart', 'chart': 'area', 'focus': 'show trend as area chart'},
            'map': {'type': 'explicit_chart', 'chart': 'choropleth', 'focus': 'show geographic distribution on map'},
            'choropleth': {'type': 'explicit_chart', 'chart': 'choropleth', 'focus': 'show geographic distribution as choropleth map'},
            'ì§€ë„': {'type': 'explicit_chart', 'chart': 'choropleth', 'focus': 'show geographic distribution on map'},
            'ì§€ë„ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'choropleth', 'focus': 'show geographic distribution as map chart'},
            'ì§€ë„ ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'choropleth', 'focus': 'show geographic distribution as map chart'},
            'ë§µì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'choropleth', 'focus': 'show geographic distribution as map chart'},
            'geo scatter': {'type': 'explicit_chart', 'chart': 'scattergeo', 'focus': 'show geographic points on map'},
            'scattergeo': {'type': 'explicit_chart', 'chart': 'scattergeo', 'focus': 'show geographic points on map'},
            'ì˜ì—­ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'area', 'focus': 'show trend as area chart'},
            'heatmap': {'type': 'explicit_chart', 'chart': 'heatmap', 'focus': 'show correlation matrix as heatmap'},
            'íˆíŠ¸ë§µ': {'type': 'explicit_chart', 'chart': 'heatmap', 'focus': 'show correlation matrix as heatmap'},
            'ì—´ì§€ë„': {'type': 'explicit_chart', 'chart': 'heatmap', 'focus': 'show correlation matrix as heatmap'},
            
            # ADVANCED STATISTICAL CHARTS
            'violin': {'type': 'explicit_chart', 'chart': 'violin', 'focus': 'show distribution as violin plot'},
            'violin plot': {'type': 'explicit_chart', 'chart': 'violin', 'focus': 'show distribution as violin plot'},
            'ë°”ì´ì˜¬ë¦°': {'type': 'explicit_chart', 'chart': 'violin', 'focus': 'show distribution as violin plot'},
            'strip plot': {'type': 'explicit_chart', 'chart': 'strip', 'focus': 'show distribution as strip plot'},
            'ìŠ¤íŠ¸ë¦½': {'type': 'explicit_chart', 'chart': 'strip', 'focus': 'show distribution as strip plot'},
            'density contour': {'type': 'explicit_chart', 'chart': 'density_contour', 'focus': 'show density as contour plot'},
            'ë°€ë„ë“±ê³ ì„ ': {'type': 'explicit_chart', 'chart': 'density_contour', 'focus': 'show density as contour plot'},
            'density heatmap': {'type': 'explicit_chart', 'chart': 'density_heatmap', 'focus': 'show density as heatmap'},
            'ë°€ë„íˆíŠ¸ë§µ': {'type': 'explicit_chart', 'chart': 'density_heatmap', 'focus': 'show density as heatmap'},
            
            # SPECIALIZED CHARTS
            'funnel': {'type': 'explicit_chart', 'chart': 'funnel', 'focus': 'show conversion as funnel chart'},
            'funnel chart': {'type': 'explicit_chart', 'chart': 'funnel', 'focus': 'show conversion as funnel chart'},
            'ê¹”ë•Œê¸°': {'type': 'explicit_chart', 'chart': 'funnel', 'focus': 'show conversion as funnel chart'},
            'waterfall': {'type': 'explicit_chart', 'chart': 'waterfall', 'focus': 'show cumulative effect as waterfall'},
            'í­í¬ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'waterfall', 'focus': 'show cumulative effect as waterfall'},
            'treemap': {'type': 'explicit_chart', 'chart': 'treemap', 'focus': 'show hierarchy as treemap'},
            'íŠ¸ë¦¬ë§µ': {'type': 'explicit_chart', 'chart': 'treemap', 'focus': 'show hierarchy as treemap'},
            'sunburst': {'type': 'explicit_chart', 'chart': 'sunburst', 'focus': 'show hierarchy as sunburst'},
            'ì„ ë²„ìŠ¤íŠ¸': {'type': 'explicit_chart', 'chart': 'sunburst', 'focus': 'show hierarchy as sunburst'},
            
            # 3D CHARTS
            '3d scatter': {'type': 'explicit_chart', 'chart': 'scatter_3d', 'focus': 'show 3D scatter plot'},
            'scatter 3d': {'type': 'explicit_chart', 'chart': 'scatter_3d', 'focus': 'show 3D scatter plot'},
            '3d ì‚°ì ë„': {'type': 'explicit_chart', 'chart': 'scatter_3d', 'focus': 'show 3D scatter plot'},
            'surface': {'type': 'explicit_chart', 'chart': 'surface', 'focus': 'show 3D surface plot'},
            'í‘œë©´ì°¨íŠ¸': {'type': 'explicit_chart', 'chart': 'surface', 'focus': 'show 3D surface plot'},
            '3d surface': {'type': 'explicit_chart', 'chart': 'surface', 'focus': 'show 3D surface plot'},
            
            # FINANCIAL CHARTS  
            'candlestick': {'type': 'explicit_chart', 'chart': 'candlestick', 'focus': 'show financial data as candlestick'},
            'ìº”ë“¤ìŠ¤í‹±': {'type': 'explicit_chart', 'chart': 'candlestick', 'focus': 'show financial data as candlestick'},
            'ohlc': {'type': 'explicit_chart', 'chart': 'ohlc', 'focus': 'show OHLC financial data'},
            
            # MULTIVARIATE CHARTS
            'parallel coordinates': {'type': 'explicit_chart', 'chart': 'parallel_coordinates', 'focus': 'show multivariate as parallel coordinates'},
            'í‰í–‰ì¢Œí‘œ': {'type': 'explicit_chart', 'chart': 'parallel_coordinates', 'focus': 'show multivariate as parallel coordinates'},
            'parallel categories': {'type': 'explicit_chart', 'chart': 'parallel_categories', 'focus': 'show categories as parallel plot'},
            'í‰í–‰ì¹´í…Œê³ ë¦¬': {'type': 'explicit_chart', 'chart': 'parallel_categories', 'focus': 'show categories as parallel plot'},
            
            # SPECIALIZED VISUALIZATION
            'radar': {'type': 'explicit_chart', 'chart': 'radar', 'focus': 'show multivariate as radar chart'},
            'radar chart': {'type': 'explicit_chart', 'chart': 'radar', 'focus': 'show multivariate as radar chart'},
            'ë ˆì´ë”': {'type': 'explicit_chart', 'chart': 'radar', 'focus': 'show multivariate as radar chart'},
            'spider': {'type': 'explicit_chart', 'chart': 'radar', 'focus': 'show multivariate as spider chart'},
            
            # DISTRIBUTION CHARTS
            'distplot': {'type': 'explicit_chart', 'chart': 'distplot', 'focus': 'show distribution with KDE'},
            'ë¶„í¬í”Œë¡¯': {'type': 'explicit_chart', 'chart': 'distplot', 'focus': 'show distribution with KDE'},
            'ecdf': {'type': 'explicit_chart', 'chart': 'ecdf', 'focus': 'show empirical cumulative distribution'},
            'ëˆ„ì ë¶„í¬': {'type': 'explicit_chart', 'chart': 'ecdf', 'focus': 'show empirical cumulative distribution'},
            
            # Distribution/Grouping patterns
            'sort by': {'type': 'distribution', 'chart': 'bar', 'focus': 'show ranked distribution'},
            'group by': {'type': 'distribution', 'chart': 'bar', 'focus': 'show categorical grouping'},
            'breakdown': {'type': 'distribution', 'chart': 'pie', 'focus': 'show proportional breakdown'},
            'distribution': {'type': 'distribution', 'chart': 'pie', 'focus': 'show data distribution'},
            'proportion': {'type': 'distribution', 'chart': 'pie', 'focus': 'show proportional distribution'},
            'percentage': {'type': 'distribution', 'chart': 'pie', 'focus': 'show percentage distribution'},
            'share': {'type': 'distribution', 'chart': 'pie', 'focus': 'show share distribution'},
            'analyze': {'type': 'distribution', 'chart': 'bar', 'focus': 'perform comprehensive analysis'},
            
            # Comparison patterns
            'compare': {'type': 'comparison', 'chart': 'bar', 'focus': 'compare across categories'},
            'vs': {'type': 'comparison', 'chart': 'bar', 'focus': 'compare alternatives'},
            'versus': {'type': 'comparison', 'chart': 'bar', 'focus': 'compare alternatives'},
            'difference': {'type': 'comparison', 'chart': 'bar', 'focus': 'show differences'},
            
            # Temporal/Trend patterns
            'trend': {'type': 'temporal', 'chart': 'line', 'focus': 'show trends over time'},
            'over time': {'type': 'temporal', 'chart': 'line', 'focus': 'show temporal patterns'},
            'timeline': {'type': 'temporal', 'chart': 'line', 'focus': 'show timeline progression'},
            'history': {'type': 'temporal', 'chart': 'line', 'focus': 'show historical data'},
            'growth': {'type': 'temporal', 'chart': 'line', 'focus': 'show growth patterns'},
            'change': {'type': 'temporal', 'chart': 'line', 'focus': 'show changes over time'},
            
            # Ranking patterns
            'top': {'type': 'ranking', 'chart': 'bar', 'focus': 'show highest values'},
            'bottom': {'type': 'ranking', 'chart': 'bar', 'focus': 'show lowest values'},
            'best': {'type': 'ranking', 'chart': 'bar', 'focus': 'show best performing'},
            'worst': {'type': 'ranking', 'chart': 'bar', 'focus': 'show worst performing'},
            'most': {'type': 'ranking', 'chart': 'bar', 'focus': 'show most frequent/common'},
            'least': {'type': 'ranking', 'chart': 'bar', 'focus': 'show least frequent'},
            'highest': {'type': 'ranking', 'chart': 'bar', 'focus': 'show highest values'},
            'lowest': {'type': 'ranking', 'chart': 'bar', 'focus': 'show lowest values'},
            
            # Statistical patterns
            'correlation': {'type': 'correlation', 'chart': 'scatter', 'focus': 'show statistical relationships'},
            'relationship': {'type': 'correlation', 'chart': 'scatter', 'focus': 'analyze relationships'},
            'impact': {'type': 'correlation', 'chart': 'scatter', 'focus': 'show impact analysis'},
            
            # Aggregation patterns
            'count': {'type': 'distribution', 'chart': 'bar', 'focus': 'show item counts'},
            'sum': {'type': 'distribution', 'chart': 'bar', 'focus': 'show sum aggregation'},
            'average': {'type': 'distribution', 'chart': 'bar', 'focus': 'show average values'},
            'total': {'type': 'distribution', 'chart': 'bar', 'focus': 'show total values'}
        }
        
        # Advanced pattern matching with context scoring
        detected_intent = self._detect_intent_with_context(question_lower, intent_patterns)
        
        # Contextual refinement based on data characteristics
        detected_intent = self._refine_intent_with_data_context(detected_intent, available_columns, question_lower)
        
        # Intelligent column mapping with semantic scoring
        suggested_columns = self._map_question_to_columns(question_lower, available_columns, column_mappings)
        print(f"ğŸ” _map_question_to_columns result: {suggested_columns}")
        
        # Final validation and optimization
        final_analysis = self._optimize_analysis_strategy(suggested_columns, detected_intent, question_lower)
        
        print(f"ğŸ¯ Intent Analysis Results:")
        print(f"   Chart Type: {final_analysis['chart_type']}")
        print(f"   Intent Type: {final_analysis['intent_type']}")
        print(f"   Confidence: {final_analysis['confidence']}")
        print(f"   X Column: {final_analysis['columns']['x']}")
        print(f"   Y Column: {final_analysis['columns']['y']}")
        print(f"   Reasoning: {final_analysis['reasoning']}")

        return {
            'suggested_columns': final_analysis['columns'],
            'analysis_focus': final_analysis['focus'],
            'chart_type': final_analysis['chart_type'],
            'intent_type': final_analysis['intent_type'],
            'confidence': final_analysis['confidence'],
            'reasoning': final_analysis['reasoning']
        }
    
    def _extract_json_from_response(self, content: str) -> Dict[str, Any]:
        """Extract JSON from mixed content response"""
        
        # Try to find JSON block in the content
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        # Try to find JSON without markdown formatting
        json_match = re.search(r'(\{[^{}]*"insights"[^{}]*\})', content, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        return None
    
    def _create_conversational_analysis(self, df: pd.DataFrame, question: str, content: str) -> Dict[str, Any]:
        """Create conversational analysis from raw AI response"""
        # Use intent analysis for smart column selection
        intent_analysis = self._analyze_user_intent(question, df.columns.tolist())
        print(f"ğŸ”„ _create_conversational_analysis intent_analysis:")
        print(f"   Chart Type: {intent_analysis.get('chart_type', 'N/A')}")
        print(f"   Suggested Columns: {intent_analysis.get('suggested_columns', {})}")
        x_col = intent_analysis['suggested_columns']['x']
        y_col = intent_analysis['suggested_columns']['y']
        
        # Clean up the content - remove JSON markers and format conversationally
        cleaned_content = content
        
        # Remove JSON code block markers
        cleaned_content = re.sub(r'```json\s*', '', cleaned_content)
        cleaned_content = re.sub(r'\s*```', '', cleaned_content)
        
        # Remove raw JSON structure if present
        cleaned_content = re.sub(r'\{\s*"insights":\s*\[', '', cleaned_content)
        cleaned_content = re.sub(r'\]\s*,?\s*"chart_type".*?\}', '', cleaned_content, flags=re.DOTALL)
        
        # Extract insights from quotes
        insight_pattern = r'"([^"]{30,})"'
        insights_found = re.findall(insight_pattern, cleaned_content)
        
        # Clean up insights and make them conversational
        conversational_insights = []
        for insight in insights_found[:6]:
            # Remove escape characters and extra whitespace
            clean_insight = insight.replace('\\"', '"').replace('\\n', ' ').strip()
            if len(clean_insight) > 20:
                conversational_insights.append(clean_insight)
        
        # If no good insights found, create meaningful ones from the content
        if not conversational_insights:
            # Try to extract meaningful sentences from the raw content
            sentences = [s.strip() for s in re.split(r'[.!?]+', cleaned_content) if len(s.strip()) > 30]
            conversational_insights = sentences[:5]
        
        # Ensure we have at least some basic insights
        if not conversational_insights:
            conversational_insights = [
                f"ë°ì´í„°ì…‹ì—ì„œ {len(df):,}ê°œì˜ ë ˆì½”ë“œì™€ {len(df.columns)}ê°œì˜ ì»¬ëŸ¼ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                f"ì£¼ìš” ì»¬ëŸ¼ìœ¼ë¡œëŠ” {', '.join(df.columns[:3])} ë“±ì´ ìˆìŠµë‹ˆë‹¤.",
                "ë°ì´í„°ì˜ íŒ¨í„´ê³¼ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
            ]
        
        # Create a conversational summary
        summary = f"'{question}' ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. "
        if conversational_insights:
            # Use the first insight as part of summary
            first_insight = conversational_insights[0]
            if len(first_insight) > 100:
                first_insight = first_insight[:100] + "..."
            summary += first_insight
        
        # Generate contextual follow-up questions
        follow_up_questions = self._generate_follow_up_questions(question, df.columns.tolist(), intent_analysis)
        
        return {
            "insights": conversational_insights,
            "chart_type": intent_analysis['chart_type'],
            "chart_columns": intent_analysis['suggested_columns'],  # Use smart analysis columns
            "summary": summary,
            "follow_up_questions": follow_up_questions
        }
    
    def _create_fallback_analysis(self, df: pd.DataFrame, question: str, content: str) -> Dict[str, Any]:
        """Create fallback analysis when JSON parsing fails - deprecated, use _create_conversational_analysis"""
        return self._create_conversational_analysis(df, question, content)
    
    def _convert_comprehensive_analysis(self, comprehensive_result: Dict[str, Any]) -> Dict[str, Any]:
        """Convert comprehensive analysis format to backward compatible format"""
        # Extract insights from various sections
        all_insights = []
        
        # Add data quality insights
        if "data_quality" in comprehensive_result:
            dq = comprehensive_result["data_quality"]
            if "assessment" in dq:
                all_insights.append(f"Data Quality: {dq['assessment']}")
            if "completeness_score" in dq:
                all_insights.append(f"Data completeness score: {dq['completeness_score']}%")
        
        # Add main insights
        if "insights" in comprehensive_result:
            all_insights.extend(comprehensive_result["insights"][:4])
        
        # Add business implications
        if "business_implications" in comprehensive_result:
            bi = comprehensive_result["business_implications"]
            if "opportunities" in bi and bi["opportunities"]:
                all_insights.append(f"Key Opportunity: {bi['opportunities'][0]}")
            if "recommendations" in bi and bi["recommendations"]:
                all_insights.append(f"Recommendation: {bi['recommendations'][0]}")
        
        # Create backward compatible structure
        return {
            "insights": all_insights[:8],  # Limit to reasonable number
            "chart_type": comprehensive_result.get("chart_type", "bar"),
            "chart_columns": comprehensive_result.get("chart_columns", {}),
            "summary": comprehensive_result.get("summary", "Comprehensive data analysis completed"),
            "comprehensive_data": comprehensive_result  # Keep full data for future use
        }
    
    def _build_dynamic_column_mapping(self, available_columns: List[str], semantic_mappings: Dict[str, List[str]]) -> Dict[str, List[str]]:
        """Build intelligent column mappings based on actual data and semantic understanding"""
        mappings = {}
        
        for col in available_columns:
            col_lower = col.lower().replace('_', ' ').replace('-', ' ')
            words = col_lower.split()
            
            # Create mappings for individual words and combinations
            for i, word1 in enumerate(words):
                if len(word1) > 2:
                    mappings[word1] = mappings.get(word1, []) + [col]
                    
                    # Create two-word combinations
                    for j in range(i+1, len(words)):
                        word2 = words[j]
                        if len(word2) > 2:
                            composite = f"{word1} {word2}"
                            mappings[composite] = mappings.get(composite, []) + [col]
        
        return mappings
    
    def _detect_intent_with_context(self, question_lower: str, intent_patterns: Dict) -> Dict[str, str]:
        """Advanced pattern matching with context scoring - prioritizes explicit chart requests"""
        pattern_scores = {}
        
        for pattern, intent in intent_patterns.items():
            score = 0
            
            if pattern in question_lower:
                # Give much higher priority to explicit chart type requests
                if intent['type'] == 'explicit_chart':
                    score += 50  # Very high priority for explicit chart requests
                else:
                    score += 10
                
                position = question_lower.find(pattern)
                score += max(0, 5 - position // 10)
            
            # Check for partial matches
            pattern_words = pattern.split()
            if all(word in question_lower for word in pattern_words):
                if intent['type'] == 'explicit_chart':
                    score += 25  # High priority even for partial matches
                else:
                    score += 5
            
            # Special handling for common chart type keywords
            if intent['type'] == 'explicit_chart':
                chart_type = intent['chart']
                if chart_type in question_lower:
                    score += 30
            
            if score > 0:
                pattern_scores[pattern] = score
        
        if pattern_scores:
            best_pattern = max(pattern_scores, key=pattern_scores.get)
            return intent_patterns[best_pattern]
        
        # Smart default based on question characteristics
        if any(word in question_lower for word in ['proportion', 'percentage', 'share', 'distribution', 'breakdown']):
            return {'type': 'distribution', 'chart': 'pie', 'focus': 'show proportional distribution'}
        elif any(word in question_lower for word in ['trend', 'over time', 'growth', 'change']):
            return {'type': 'temporal', 'chart': 'line', 'focus': 'show trends over time'}
        elif any(word in question_lower for word in ['correlation', 'relationship', 'vs', 'versus']):
            return {'type': 'correlation', 'chart': 'scatter', 'focus': 'show relationships'}
        
        return {'type': 'distribution', 'chart': 'bar', 'focus': 'analyze data distribution'}
    
    def _refine_intent_with_data_context(self, intent: Dict, available_columns: List[str], question: str) -> Dict:
        """Refine intent based on data characteristics"""
        # Enhance focus based on domain context
        if any(term in question.lower() for term in ['failure', 'error', 'problem']):
            intent['focus'] = intent['focus'].replace('show', 'analyze failure patterns in')
            
        if any(term in question.lower() for term in ['success', 'complete', 'approved']):
            intent['focus'] = intent['focus'].replace('show', 'analyze success patterns in')
        
        return intent
    
    def _map_question_to_columns(self, question: str, available_columns: List[str], column_mappings: Dict) -> Dict[str, str]:
        """Intelligent semantic mapping of questions to columns"""
        column_scores = {}
        
        # Check chart type requests
        is_scatter_request = any(term in question.lower() for term in ['scatter', 'ì‚°í¬ë„', 'ì‚°ì ë„', 'correlation', 'ìƒê´€ê´€ê³„'])
        is_histogram_request = any(term in question.lower() for term in ['histogram', 'íˆìŠ¤í† ê·¸ë¨', 'distribution', 'ë¶„í¬'])
        is_heatmap_request = any(term in question.lower() for term in ['heatmap', 'íˆíŠ¸ë§µ', 'ì—´ì§€ë„', 'correlation matrix', 'ìƒê´€ê´€ê³„'])
        is_recommendation_request = any(term in question.lower() for term in [
            'ì¶”ì²œ', 'recommend', 'ì œì•ˆ', 'suggest', 'ì–´ë–¤ ì°¨íŠ¸', 'what chart', 'ë¬´ìŠ¨ ì°¨íŠ¸', 'ì¢‹ì€ ì°¨íŠ¸', 
            'ì í•©í•œ ì°¨íŠ¸', 'ìµœì ', 'optimal', 'best', 'ë¶„ì„ ë°©ë²•', 'analysis method'
        ])
        
        for col in available_columns:
            score = 0
            col_lower = col.lower()
            
            # Direct word matches
            question_words = question.split()
            col_words = col_lower.replace('_', ' ').replace('-', ' ').split()
            
            # Score based on word matches
            for qw in question_words:
                for cw in col_words:
                    if qw == cw:
                        score += 10
                    elif qw in cw or cw in qw:
                        score += 5
            
            # Business logic scoring
            if 'failure' in question and 'message' in col_lower:
                score += 15
            if 'card' in question and 'network' in col_lower:
                score += 12
            if 'country' in question and 'country' in col_lower:
                score += 12
            if 'reason' in question and 'message' in col_lower:
                score += 10
                
            # Penalize ID columns unless specifically asked
            if 'id' in col_lower and 'id' not in question:
                score -= 5
            
            column_scores[col] = score
        
        # Special handling for different chart types
        if is_scatter_request:
            # Enhanced logic for correlation analysis - can be categorical vs numeric
            correlation_keywords = ['ìƒê´€ê´€ê³„', 'ìƒê´€ì„±', 'correlation', 'ê´€ê³„', 'ì—°ê´€', 'vs', 'versus', 'ê°„ì˜']
            is_correlation_analysis = any(keyword in question for keyword in correlation_keywords)

            if is_correlation_analysis:
                # For correlation, identify categorical and numeric columns from the question
                age_keywords = ['ë‚˜ì´', 'age', 'ì—°ë ¹', 'class']
                weight_keywords = ['ë¬´ê²Œ', 'weight', 'ì²´ì¤‘', 'kg']

                categorical_col = None
                numeric_col = None

                # Find Age Class column
                for col in available_columns:
                    if any(age_kw in col.lower() for age_kw in age_keywords):
                        categorical_col = col
                        break

                # Find Weight column
                for col in available_columns:
                    if any(weight_kw in col.lower() for weight_kw in weight_keywords):
                        numeric_col = col
                        break

                # Use the identified columns if found
                if categorical_col and numeric_col:
                    result = {'x': categorical_col, 'y': numeric_col}
                    print(f"ğŸ¯ Found correlation pair: {categorical_col} vs {numeric_col}")
                    print(f"ğŸ¯ Returning correlation result: {result}")
                    return result

                # Fallback: try to match any mentioned columns in the question
                question_words = question.lower().split()
                mentioned_cols = []
                for col in available_columns:
                    col_words = col.lower().replace('_', ' ').replace('-', ' ').split()
                    if any(qw in col_words or any(qw in cw or cw in qw for cw in col_words) for qw in question_words):
                        mentioned_cols.append(col)

                if len(mentioned_cols) >= 2:
                    # Prioritize categorical vs numeric combination
                    numeric_columns = self._identify_numeric_columns(mentioned_cols)
                    categorical_columns = [col for col in mentioned_cols if col not in numeric_columns]

                    if categorical_columns and numeric_columns:
                        print(f"ğŸ¯ Using categorical vs numeric: {categorical_columns[0]} vs {numeric_columns[0]}")
                        return {'x': categorical_columns[0], 'y': numeric_columns[0]}
                    else:
                        print(f"ğŸ¯ Using first two mentioned columns: {mentioned_cols[0]} vs {mentioned_cols[1]}")
                        return {'x': mentioned_cols[0], 'y': mentioned_cols[1]}

            # Original scatter plot logic for non-correlation requests
            numeric_columns = self._identify_numeric_columns(available_columns)
            if len(numeric_columns) >= 2:
                # Use the two best numeric columns for scatter plot
                x_col = numeric_columns[0]
                y_col = numeric_columns[1]

                # If question mentions specific columns, try to use those
                for col in numeric_columns:
                    if any(word in col.lower() for word in question.lower().split()):
                        if x_col == numeric_columns[0]:  # First match becomes x
                            x_col = col
                        else:  # Second match becomes y
                            y_col = col
                            break

                return {'x': x_col, 'y': y_col}
            else:
                # Fallback: use best scored column with a numeric column if available
                best_col = max(column_scores, key=column_scores.get) if column_scores else available_columns[0]
                if numeric_columns:
                    return {'x': best_col, 'y': numeric_columns[0]}
                return {'x': best_col, 'y': 'Count'}
        
        elif is_histogram_request:
            # Histogram only needs one numeric column
            numeric_columns = self._identify_numeric_columns(available_columns)
            if numeric_columns:
                # Find the best numeric column based on question
                best_numeric = numeric_columns[0]
                for col in numeric_columns:
                    if any(word in col.lower() for word in question.lower().split()):
                        best_numeric = col
                        break
                return {'x': best_numeric, 'y': 'Count'}
            else:
                # No numeric columns available
                best_col = max(column_scores, key=column_scores.get) if column_scores else available_columns[0]
                return {'x': best_col, 'y': 'Count'}
        
        elif is_heatmap_request:
            # Heatmap doesn't need specific x,y columns - uses all numeric columns
            numeric_columns = self._identify_numeric_columns(available_columns)
            if len(numeric_columns) >= 2:
                return {'x': 'all_numeric', 'y': 'all_numeric'}
            else:
                return {'x': 'insufficient_numeric', 'y': 'insufficient_numeric'}
        
        elif is_recommendation_request:
            # Return special marker for recommendation requests
            return {'x': 'recommendation_request', 'y': 'recommendation_request'}
        
        # Select best column for non-scatter charts
        if column_scores and max(column_scores.values()) > 0:
            best_col = max(column_scores, key=column_scores.get)
            return {'x': best_col, 'y': 'Count'}
        
        # Fallback logic
        priority_indicators = ['message', 'status', 'type', 'network', 'country', 'reason']
        for indicator in priority_indicators:
            for col in available_columns:
                if indicator in col.lower() and 'id' not in col.lower():
                    return {'x': col, 'y': 'Count'}
        
        # Final fallback
        non_id_cols = [col for col in available_columns if 'id' not in col.lower()]
        if non_id_cols:
            return {'x': non_id_cols[0], 'y': 'Count'}
        
        return {'x': available_columns[0] if available_columns else 'unknown', 'y': 'Count'}
    
    def _identify_numeric_columns(self, available_columns: List[str]) -> List[str]:
        """Identify potentially numeric columns based on column names"""
        numeric_indicators = [
            'amount', 'value', 'price', 'cost', 'fee', 'rate', 'count', 'number', 'num', 
            'quantity', 'size', 'length', 'width', 'height', 'weight', 'age', 'score',
            'total', 'sum', 'avg', 'mean', 'max', 'min', 'percentage', 'percent', '%'
        ]
        
        numeric_columns = []
        for col in available_columns:
            col_lower = col.lower()
            # Skip ID columns
            if 'id' in col_lower:
                continue
            # Check for numeric indicators
            if any(indicator in col_lower for indicator in numeric_indicators):
                numeric_columns.append(col)
            # Check if column name suggests it's numeric (ends with numbers, etc.)
            elif any(char.isdigit() for char in col_lower):
                numeric_columns.append(col)
        
        return numeric_columns
    
    def _optimize_analysis_strategy(self, columns: Dict, intent: Dict, question: str) -> Dict:
        """Final optimization of analysis strategy with enhanced categorical-numeric handling"""
        print(f"ğŸ”§ _optimize_analysis_strategy input - columns: {columns}")
        confidence = 0.5
        reasoning = ["Basic analysis strategy"]

        if columns['x'] != 'unknown':
            confidence += 0.2
            reasoning.append(f"Found relevant column: {columns['x']}")

        # Boost confidence for clear intents
        clear_intents = ['sort by', 'group by', 'breakdown', 'compare', 'trend']
        if any(intent_word in question for intent_word in clear_intents):
            confidence += 0.3
            reasoning.append("Clear user intent detected")

        # Enhanced correlation/relationship analysis for categorical-numeric data
        correlation_keywords = ['ìƒê´€ê´€ê³„', 'ìƒê´€ì„±', 'correlation', 'relationship', 'ê´€ê³„', 'ì—°ê´€', 'vs', 'versus', 'ê°„ì˜']
        if any(keyword in question.lower() for keyword in correlation_keywords):
            confidence += 0.4
            reasoning.append("Correlation analysis detected")

        # Use original intent chart type (don't force box plot)
        chart_type = intent['chart']

        # Domain-specific optimizations
        if 'failure' in question.lower() and 'message' in columns['x'].lower():
            confidence = 0.9
            reasoning.append("Perfect match: failure analysis with message column")

        # Age class analysis optimization - keep original chart type but boost confidence
        age_keywords = ['ë‚˜ì´', 'age', 'ì—°ë ¹', 'class']
        weight_keywords = ['ë¬´ê²Œ', 'weight', 'ì²´ì¤‘', 'kg']
        if (any(age_kw in question.lower() for age_kw in age_keywords) and
            any(weight_kw in question.lower() for weight_kw in weight_keywords)):
            confidence = 0.95
            reasoning.append("Age-weight analysis detected: high confidence")

        # Distribution optimization (but preserve special chart types like box)
        if intent['type'] == 'distribution' and chart_type not in ['bar', 'pie', 'box', 'violin', 'histogram']:
            chart_type = 'bar'
            reasoning.append("Optimized chart type for distribution")

        result = {
            'columns': columns,
            'focus': f"{intent['focus']} of {columns['x']}" + (f" vs {columns['y']}" if columns['y'] != 'unknown' else ""),
            'chart_type': chart_type,
            'intent_type': intent['type'],
            'confidence': min(1.0, confidence),
            'reasoning': reasoning
        }
        print(f"ğŸ”§ _optimize_analysis_strategy result - columns: {result['columns']}")
        return result
    
    async def answer_general_question(self, question: str) -> str:
        """íŒŒì¼ ì—†ì´ ì¼ë°˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. ì‹œë‚˜ë¦¬ì˜¤, ê°€ì •, í‘œ ìƒì„± ë“±ì„ í¬í•¨í•œ í¬ê´„ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."""
        try:
            # Check if API key is properly set
            if not settings.OPENAI_API_KEY or settings.OPENAI_API_KEY == "your_openai_api_key_here":
                return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

            # ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ë° ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
            enhanced_prompt = self._create_enhanced_general_prompt(question)

            response = self.client.chat.completions.create(
                model="gpt-4o",  # ë” ê°•ë ¥í•œ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {
                        "role": "system",
                        "content": enhanced_prompt
                    },
                    {"role": "user", "content": question}
                ],
                temperature=0.7,
                max_tokens=2000  # ë” ê¸´ ì‘ë‹µ í—ˆìš©
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            print(f"General question AI error: {str(e)}")
            return f"ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _create_enhanced_general_prompt(self, question: str) -> str:
        """ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ë§ì¶¤í˜• ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        question_lower = question.lower()

        # ì‹œë‚˜ë¦¬ì˜¤/ê°€ì • ê¸°ë°˜ ì§ˆë¬¸ ê°ì§€
        scenario_keywords = ['ê°€ì •', 'ì‹œë‚˜ë¦¬ì˜¤', 'ë§Œì•½', 'if', 'suppose', 'ìƒí™©', 'ê²½ìš°', 'ì˜ˆë¥¼ ë“¤ì–´', 'ê°€ë ¹']
        table_keywords = ['í‘œ', 'table', 'í…Œì´ë¸”', 'ë°ì´í„°', 'ëª©ë¡', 'list', 'ë¹„êµ', 'ì •ë¦¬', 'ìš”ì•½']
        logic_keywords = ['ë¡œì§', 'logic', 'ë°©ë²•', 'ì ˆì°¨', 'ë‹¨ê³„', 'step', 'í”„ë¡œì„¸ìŠ¤', 'process', 'ì•Œê³ ë¦¬ì¦˜']
        analysis_keywords = ['ë¶„ì„', 'analysis', 'í•´ì„', 'í‰ê°€', 'ê²€í† ', 'ì¡°ì‚¬', 'ì—°êµ¬']
        calculation_keywords = ['ê³„ì‚°', 'ìˆ˜ì¹˜', 'í†µê³„', 'ì˜ˆìƒ', 'ì¶”ì •', 'ì¸¡ì •']

        is_scenario = any(keyword in question_lower for keyword in scenario_keywords)
        is_table = any(keyword in question_lower for keyword in table_keywords)
        is_logic = any(keyword in question_lower for keyword in logic_keywords)
        is_analysis = any(keyword in question_lower for keyword in analysis_keywords)
        is_calculation = any(keyword in question_lower for keyword in calculation_keywords)

        base_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” AI ë°ì´í„° ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        if is_scenario:
            return base_prompt + """

**ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ:**
- ì œì‹œëœ ê°€ì •ì´ë‚˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”
- ê°€ëŠ¥í•œ ê²°ê³¼ì™€ ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ì‹¤ì œ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì–´ë–»ê²Œ ë¶„ì„í• ì§€ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”
- ì—¬ëŸ¬ ê´€ì ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê²€í† í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”
- í•„ìš”ì‹œ ì˜ˆì‹œ ë°ì´í„°ë‚˜ ìƒ˜í”Œ í…Œì´ë¸”ì„ í¬í•¨í•˜ì„¸ìš”
- ìˆ˜í•™ì  ê³„ì‚°ì´ë‚˜ ê³µì‹ì´ í•„ìš”í•œ ê²½ìš° LaTeX ìˆ˜ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: $\\frac{ë³€í™”ëŸ‰}{ê¸°ì¤€ê°’} \\times 100$)

ë‹µë³€ í˜•ì‹:
1. ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½
2. ì£¼ìš” ê°€ì •ì‚¬í•­
3. ì˜ˆìƒ ê²°ê³¼ ë° ì˜í–¥
4. ë¶„ì„ ë°©ë²•ë¡ 
5. ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì‚¬í•­"""

        elif is_table:
            return base_prompt + """

**í‘œ/ë°ì´í„° êµ¬ì¡° ì „ë¬¸ê°€ë¡œì„œ:**
- ìš”ì²­ëœ ì •ë³´ë¥¼ ì²´ê³„ì ì¸ í‘œ í˜•íƒœë¡œ ì •ë¦¬í•˜ì„¸ìš”
- ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì»¬ëŸ¼ê³¼ í–‰ì„ ë…¼ë¦¬ì ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”
- í‘œì— ëŒ€í•œ ì„¤ëª…ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”
- ì‹¤ì œ ë°ì´í„° ë¶„ì„ ì‹œ ê³ ë ¤ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”

í‘œ í˜•ì‹ ì˜ˆì‹œ:
| í•­ëª© | ê°’1 | ê°’2 | ì„¤ëª… |
|------|-----|-----|------|
| ... | ... | ... | ... |

í‘œ í›„ì—ëŠ” ì£¼ìš” íŒ¨í„´ì´ë‚˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."""

        elif is_logic:
            return base_prompt + """

**ë¡œì§/í”„ë¡œì„¸ìŠ¤ ì„¤ê³„ ì „ë¬¸ê°€ë¡œì„œ:**
- ë‹¨ê³„ë³„ë¡œ ëª…í™•í•œ ì ˆì°¨ë¥¼ ì œì‹œí•˜ì„¸ìš”
- ê° ë‹¨ê³„ì˜ ëª©ì ê³¼ ë°©ë²•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ì‹¤ì œ êµ¬í˜„ ì‹œ ê³ ë ¤ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”
- ê°€ëŠ¥í•œ ë¬¸ì œì ê³¼ í•´ê²°ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
- ë°ì´í„° ë¶„ì„ ê´€ì ì—ì„œì˜ ì ‘ê·¼ë²•ì„ í¬í•¨í•˜ì„¸ìš”

ë‹µë³€ í˜•ì‹:
1. ê°œìš” ë° ëª©í‘œ
2. ë‹¨ê³„ë³„ ìƒì„¸ ì ˆì°¨
3. ê° ë‹¨ê³„ë³„ ê³ ë ¤ì‚¬í•­
4. ì˜ˆìƒ ê²°ê³¼ë¬¼
5. í’ˆì§ˆ ê²€ì¦ ë°©ë²•"""

        elif is_analysis:
            return base_prompt + """

**ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ:**
- ì£¼ì œì— ëŒ€í•œ ë‹¤ê°ë„ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”
- ì •ëŸ‰ì /ì •ì„±ì  ê´€ì ì„ ëª¨ë‘ ê³ ë ¤í•˜ì„¸ìš”
- ì‹¤ì œ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì–´ë–¤ ì°¨íŠ¸ë‚˜ ì§€í‘œê°€ ìœ ìš©í• ì§€ ì œì•ˆí•˜ì„¸ìš”
- ë¹„ì¦ˆë‹ˆìŠ¤ ë˜ëŠ” ì‹¤ë¬´ì  ê´€ì ì—ì„œì˜ ì‹œì‚¬ì ì„ ë„ì¶œí•˜ì„¸ìš”
- ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•œ ì˜ì—­ì„ ì‹ë³„í•˜ì„¸ìš”

ë‹µë³€ í˜•ì‹:
1. í˜„í™© ë¶„ì„
2. í•µì‹¬ ìš”ì¸ ì‹ë³„
3. íŒ¨í„´ ë° íŠ¸ë Œë“œ
4. ìœ„í—˜ìš”ì†Œ ë° ê¸°íšŒ
5. ê°œì„  ë°©í–¥ ì œì•ˆ"""

        elif is_calculation:
            return base_prompt + """

**ìˆ˜ì¹˜ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ:**
- ê´€ë ¨ëœ ê³„ì‚°ì´ë‚˜ ìˆ˜ì¹˜ì  ì ‘ê·¼ë²•ì„ ì œì‹œí•˜ì„¸ìš”
- ê°€ì •ì‚¬í•­ì„ ëª…í™•íˆ í•˜ê³  ê³„ì‚° ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”
- í†µê³„ì  ê´€ì ì—ì„œì˜ í•´ì„ì„ í¬í•¨í•˜ì„¸ìš”
- ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œ í•„ìš”í•œ ì§€í‘œë¥¼ ì œì•ˆí•˜ì„¸ìš”
- ê²°ê³¼ ê²€ì¦ ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”
- ìˆ˜í•™ ê³µì‹ì€ LaTeXë¡œ í‘œí˜„í•˜ì„¸ìš” (ì˜ˆ: $\\mu = \\frac{\\sum x_i}{n}$, $$\\sigma = \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{n}}$$)

ë‹µë³€ì— í¬í•¨í•  ìš”ì†Œ:
- ê¸°ë³¸ ê°€ì •ì‚¬í•­
- ê³„ì‚° ê³µì‹ ë° ë°©ë²• (LaTeX ìˆ˜ì‹ í¬í•¨)
- ì˜ˆì‹œ ê³„ì‚°
- ê²°ê³¼ í•´ì„
- í™œìš© ë°©ì•ˆ"""

        else:
            return base_prompt + """

**ì¢…í•© ì»¨ì„¤í„´íŠ¸ë¡œì„œ:**
- ì§ˆë¬¸ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
- ì´ë¡ ì  ì„¤ëª…ê³¼ ì‹¤ë¬´ì  ì ìš© ë°©ë²•ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”
- ê´€ë ¨ëœ ì‚¬ë¡€ë‚˜ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì„¸ìš”
- ì‹¤ì œ ë°ì´í„° ë¶„ì„ ì‹œ ë„ì›€ì´ ë  ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”
- í›„ì† ì§ˆë¬¸ì´ë‚˜ ì‹¬í™” ë¶„ì„ ë°©í–¥ì„ ì œì•ˆí•˜ì„¸ìš”
- ìˆ˜í•™ì  ì„¤ëª…ì´ í•„ìš”í•œ ê²½ìš° LaTeX ìˆ˜ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$)

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."""
    
    async def generate_chat_title(self, first_message: str) -> str:
        """ì‚¬ìš©ìì˜ ì²« ë©”ì‹œì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì±„íŒ… ì œëª©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # Check if API key is properly set
            if not settings.OPENAI_API_KEY or settings.OPENAI_API_KEY == "your_openai_api_key_here":
                return "ìƒˆ ì±„íŒ…"
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": """ë‹¹ì‹ ì€ ì±„íŒ… ì œëª©ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì²« ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê°„ê²°í•˜ê³  ì˜ë¯¸ìˆëŠ” ì±„íŒ… ì œëª©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ì œëª©ì€ 3-6ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
2. í•µì‹¬ ë‚´ìš©ì„ ëª…í™•íˆ í‘œí˜„
3. í•œêµ­ì–´ë¡œ ì‘ì„±
4. íŠ¹ìˆ˜ë¬¸ìë‚˜ ë”°ì˜´í‘œ ì—†ì´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ì„±
5. ë°ì´í„° ë¶„ì„ ê´€ë ¨ ì§ˆë¬¸ì´ë©´ ë¶„ì„ ì£¼ì œë¥¼ í¬í•¨

ì˜ˆì‹œ:
- ì…ë ¥: "ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”" â†’ ì¶œë ¥: "ë§¤ì¶œ ë°ì´í„° ë¶„ì„"
- ì…ë ¥: "ê³ ê° ë§Œì¡±ë„ëŠ” ì–´ë–»ê²Œ ì¸¡ì •í•˜ë‚˜ìš”?" â†’ ì¶œë ¥: "ê³ ê° ë§Œì¡±ë„ ì¸¡ì • ë°©ë²•"
- ì…ë ¥: "Pythonìœ¼ë¡œ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” ë°©ë²•" â†’ ì¶œë ¥: "Python ì°¨íŠ¸ ê·¸ë¦¬ê¸°"
"""
                    },
                    {"role": "user", "content": f"ë‹¤ìŒ ë©”ì‹œì§€ì˜ ì œëª©ì„ ìƒì„±í•´ì£¼ì„¸ìš”: {first_message}"}
                ],
                temperature=0.3,
                max_tokens=50
            )
            
            title = response.choices[0].message.content.strip()
            
            # ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸° (ìµœëŒ€ 30ì)
            if len(title) > 30:
                title = title[:30] + "..."
            
            # ë¹ˆ ì œëª©ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ê¸°ë³¸ ì œëª© ë°˜í™˜
            if not title or len(title) < 3:
                return "ìƒˆ ì±„íŒ…"
                
            return title
            
        except Exception as e:
            print(f"Chat title generation AI error: {str(e)}")
            return "ìƒˆ ì±„íŒ…"

    async def analyze_with_code_execution(self, df: pd.DataFrame, question: str) -> Dict[str, Any]:
        """ì½”ë“œ ì‹¤í–‰ì„ í†µí•œ ì •í™•í•œ ë°ì´í„° ë¶„ì„"""
        try:
            # ì§ˆë¬¸ì—ì„œ ê³„ì‚°ì´ í•„ìš”í•œì§€ í™•ì¸
            calculation_keywords = ['í‰ê· ', 'average', 'ì´í•©', 'sum', 'ê°œìˆ˜', 'count', 'ìµœëŒ€', 'max', 'ìµœì†Œ', 'min', 'í‘œì¤€í¸ì°¨', 'std']
            needs_calculation = any(keyword in question.lower() for keyword in calculation_keywords)

            if not needs_calculation:
                # ì¼ë°˜ ë¶„ì„ìœ¼ë¡œ ì²˜ë¦¬
                return await self.analyze_data(df, question)

            # ì½”ë“œ ìƒì„±ì„ ìœ„í•œ AI í”„ë¡¬í”„íŠ¸
            code_generation_prompt = f"""
ë°ì´í„° ë¶„ì„ ì§ˆë¬¸: "{question}"

ë‹¤ìŒ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì •í™•í•œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ë°ì´í„° ì •ë³´:
- í–‰ ìˆ˜: {len(df):,}
- ì—´ ìˆ˜: {len(df.columns)}
- ì»¬ëŸ¼: {df.columns.tolist()}
- ìƒ˜í”Œ ë°ì´í„°: {df.head(3).to_dict()}

ìš”êµ¬ì‚¬í•­:
1. pandasì™€ numpyë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ê³„ì‚°
2. ê²°ê³¼ë¥¼ ëª…í™•íˆ ì¶œë ¥í•˜ëŠ” print ë¬¸ í¬í•¨
3. LaTeX ìˆ˜ì‹ìœ¼ë¡œ ê³µì‹ ì„¤ëª… í¬í•¨
4. ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ì§„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ

ì½”ë“œë§Œ ë°˜í™˜í•˜ê³  ì„¤ëª…ì€ ìµœì†Œí™”í•˜ì„¸ìš”.
"""

            # AIì—ê²Œ ì½”ë“œ ìƒì„± ìš”ì²­
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Python ë°ì´í„° ë¶„ì„ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": code_generation_prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )

            generated_code = response.choices[0].message.content.strip()

            # ìƒì„±ëœ ì½”ë“œë¥¼ ì²­í¬ë¡œ ë¶„í• 
            code_chunks = self._split_code_into_chunks(generated_code)

            # ì½”ë“œ ì‹¤í–‰ì„ í†µí•œ ì‹¤ì œ ê³„ì‚°
            execution_result = await self._execute_analysis_code(generated_code, df)

            # ê²°ê³¼ í¬ë§·íŒ…
            analysis_result = {
                'answer': execution_result.get('output', ''),
                'code_execution': {
                    'codeChunks': code_chunks,
                    'isExecuting': False,
                    'result': execution_result.get('result', '')
                },
                'insights': [
                    f"âœ… ì½”ë“œ ì‹¤í–‰ì„ í†µí•œ ì •í™•í•œ ê³„ì‚° ê²°ê³¼ì…ë‹ˆë‹¤.",
                    f"âš¡ ì‹¤í–‰ ì‹œê°„: {execution_result.get('execution_time', 0):.2f}ì´ˆ",
                    "ğŸ“Š ëª¨ë“  ìˆ˜ì¹˜ëŠ” ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤."
                ]
            }

            if execution_result.get('error'):
                analysis_result['insights'].append(f"âš ï¸ ì‹¤í–‰ ì¤‘ ê²½ê³ : {execution_result['error']}")

            return analysis_result

        except Exception as e:
            print(f"Code execution analysis error: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ í´ë°±
            return await self.analyze_data(df, question)

    def _split_code_into_chunks(self, code: str) -> List[str]:
        """ì½”ë“œë¥¼ ì‹¤í–‰ ë‹¨ìœ„ë³„ë¡œ ë¶„í• """
        # ë°±í‹± ì œê±°
        code = code.strip()
        if code.startswith('```python'):
            code = code[9:]
        if code.startswith('```'):
            code = code[3:]
        if code.endswith('```'):
            code = code[:-3]

        lines = code.split('\n')
        chunks = []
        current_chunk = []

        for i, line in enumerate(lines):
            current_chunk.append(line)

            # ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ ì²­í¬ ë¶„í• 
            is_break_point = (
                line.strip().startswith('import ') or  # import ë¬¸
                line.strip().startswith('from ') or   # from import ë¬¸
                line.strip().startswith('#') or       # ì£¼ì„
                (line.strip().startswith('print(') and line.strip().endswith(')')) or  # ì™„ì „í•œ print ë¬¸
                (line.strip() == '' and i > 0 and lines[i-1].strip() != '') or  # ë¹ˆ ì¤„ (ì—°ì† ë¹ˆ ì¤„ ì œì™¸)
                (i == len(lines) - 1)  # ë§ˆì§€ë§‰ ì¤„
            )

            if is_break_point and current_chunk:
                chunk_text = '\n'.join(current_chunk).strip()
                if chunk_text:
                    chunks.append(chunk_text)
                current_chunk = []

        # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
        if current_chunk:
            chunk_text = '\n'.join(current_chunk).strip()
            if chunk_text:
                chunks.append(chunk_text)

        # ë¹ˆ ì²­í¬ ì œê±° ë° ìµœì†Œ 1ê°œ ì²­í¬ ë³´ì¥
        chunks = [chunk for chunk in chunks if chunk.strip()]
        if not chunks and code.strip():
            chunks = [code.strip()]

        return chunks

    async def _execute_analysis_code(self, code: str, df: pd.DataFrame) -> Dict[str, Any]:
        """ë¶„ì„ ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰"""
        try:
            # ì½”ë“œ ì‹¤í–‰ API í˜¸ì¶œ
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "http://localhost:8000/api/code/execute",
                    json={
                        "code": code,
                        "context": {
                            "data": df.to_dict(),  # ë°ì´í„°í”„ë ˆì„ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì „ë‹¬
                            "df": df.to_dict()  # í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
                        }
                    },
                    timeout=30.0
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    return {
                        "success": False,
                        "output": "",
                        "error": f"ì‹¤í–‰ ì‹¤íŒ¨: {response.status_code}",
                        "execution_time": 0
                    }

        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                "execution_time": 0
            }

    async def unified_analysis(self, question: str, df: pd.DataFrame = None, file_info: dict = None, conversation_history: list = None) -> Dict[str, Any]:
        """
        í†µí•©ëœ ë¶„ì„ ì‹œìŠ¤í…œ - ëª¨ë“  ì§ˆë¬¸ì„ ì½”ë“œ ì‹¤í–‰ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
        íŒŒì¼ ìœ ë¬´ì— ê´€ê³„ì—†ì´ ì •í™•í•œ ê³„ì‚°ê³¼ ë¶„ì„ ì œê³µ
        """
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì²˜ë¦¬
            enhanced_question = self._enhance_question_with_context(question, conversation_history)
            print(f"ğŸ”„ Enhanced question with context: {enhanced_question}")

            # ì§ˆë¬¸ ë¶„ì„ ë° ì½”ë“œ ìƒì„±
            if df is not None and not df.empty:
                # íŒŒì¼ì´ ìˆëŠ” ê²½ìš°: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„
                analysis_result = await self._generate_data_analysis_code(enhanced_question, df, file_info)
            else:
                # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°: ì¼ë°˜ì ì¸ ê³„ì‚°/ë¶„ì„ ì½”ë“œ
                analysis_result = await self._generate_general_analysis_code(enhanced_question)

            # ê´€ë ¨ ì§ˆë¬¸ ìƒì„± (ëª¨ë“  ê²½ìš°ì— ìƒì„±)
            follow_up_questions = await self._generate_follow_up_questions(question, analysis_result)

            # ì½”ë“œ ì²­í¬ê°€ ìˆìœ¼ë©´ ì‹¤í–‰ ìƒíƒœë¡œ ì„¤ì •
            code_chunks = analysis_result.get('code_chunks', [])
            is_executing = len(code_chunks) > 0

            # ì½”ë“œ ì‹¤í–‰ì´ ìˆìœ¼ë©´ ë‹µë³€ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì‹œì‘ (ì½”ë“œ ì‹¤í–‰ í›„ ì±„ì›Œì§ˆ ì˜ˆì •)
            if is_executing:
                answer = ""  # ì½”ë“œ ì‹¤í–‰ ì „ì—ëŠ” ë‹µë³€ ì—†ìŒ
            else:
                answer = analysis_result.get('output', '')
                if not answer and not analysis_result.get('success', True):
                    answer = f"ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {analysis_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                elif not answer:
                    answer = "ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."

            result = {
                'answer': answer,
                'code_execution': {
                    'codeChunks': code_chunks,
                    'isExecuting': is_executing,
                    'result': analysis_result.get('result', ''),
                    'output': analysis_result.get('output', '')  # ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³„ë„ë¡œ ì €ì¥
                },
                'insights': analysis_result.get('insights', []),
                'followUpQuestions': follow_up_questions
            }

            # ì°¨íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if analysis_result.get('chart_data'):
                result['chartData'] = analysis_result['chart_data']

            return result

        except Exception as e:
            print(f"Unified analysis error: {str(e)}")
            return {
                'answer': f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'code_execution': {
                    'codeChunks': [],
                    'isExecuting': False,
                    'result': ''
                },
                'insights': [],
                'followUpQuestions': []
            }

    async def _generate_data_analysis_code(self, question: str, df: pd.DataFrame, file_info: dict) -> Dict[str, Any]:
        """íŒŒì¼ì´ ìˆëŠ” ê²½ìš° ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì½”ë“œ ìƒì„± - ìŠ¤ë§ˆíŠ¸ ì»¬ëŸ¼ ë§¤í•‘"""

        # AI ê¸°ë°˜ ìœ ì—°í•œ ì½”ë“œ ìƒì„±
        columns = df.columns.tolist()

        # ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
        column_info = {}
        for col in columns:
            try:
                unique_values = df[col].dropna().unique()
                sample_values = list(unique_values[:5]) if len(unique_values) > 0 else []
                column_info[col] = {
                    'type': str(df[col].dtype),
                    'sample_values': sample_values,
                    'unique_count': len(unique_values),
                    'null_count': df[col].isnull().sum()
                }
            except:
                column_info[col] = {'type': 'unknown', 'sample_values': [], 'unique_count': 0, 'null_count': 0}

        # AIì—ê²Œ ì§ì ‘ ì½”ë“œ ìƒì„± ìš”ì²­
        generated_code = await self._generate_flexible_analysis_code(question, df, column_info)
        analysis_type = "ai_generated"

        # ê¸°ì¡´ í•˜ë“œì½”ë”©ëœ ë¶„ì„ íƒ€ì…ë“¤ì„ ì£¼ì„ ì²˜ë¦¬í•˜ê³  AI ìƒì„±ìœ¼ë¡œ ëŒ€ì²´
        # if column_mapping.get("analysis_type") == "gender_analysis" and column_mapping.get("target_column"):
            sex_column = column_mapping["target_column"]
            analysis_type = "gender_analysis"
            generated_code = f"""import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json

# ì„±ë³„ ë¶„í¬ ë¶„ì„
print("=== ì„±ë³„ ë¶„í¬ ë¶„ì„ ===")
sex_counts = df['{sex_column}'].value_counts()
print("ì„±ë³„ë³„ ê°œì²´ ìˆ˜:")
for gender, cnt in sex_counts.items():
    percentage = (cnt / len(df)) * 100
    print(f"  {gender}: {cnt:,}ë§ˆë¦¬ ({percentage:.1f}%)")

print(f"ì´ ë¶„ì„ ê°œì²´ ìˆ˜: {len(df):,}ë§ˆë¦¬")

# Plotly ë°” ì°¨íŠ¸ ìƒì„±
fig = px.bar(
    x=sex_counts.index,
    y=sex_counts.values,
    labels={{'x': 'ì„±ë³„', 'y': 'ê°œì²´ ìˆ˜'}},
    title='{sex_column} ê¸°ì¤€ ê°œì²´ ìˆ˜ ë¶„í¬',
    color=sex_counts.values,
    color_continuous_scale='viridis'
)

fig.update_layout(
    xaxis_title='ì„±ë³„',
    yaxis_title='ê°œì²´ ìˆ˜',
    showlegend=False,
    height=500
)

# ì°¨íŠ¸ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
chart_json = fig.to_json()
print("ğŸ“Š ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")"""

        # ë‚˜ì´/ì—°ë ¹ ë¶„ì„
        elif column_mapping.get("analysis_type") == "age_analysis" and column_mapping.get("target_column"):
            age_column = column_mapping["target_column"]
            analysis_type = "age_analysis"
            generated_code = f"""import pandas as pd
import plotly.express as px
import numpy as np

# ì—°ë ¹ ë¶„í¬ ë¶„ì„
print("=== ì—°ë ¹ ë¶„í¬ ë¶„ì„ ===")
ages = df['{age_column}'].dropna()
print(f"í‰ê·  ì—°ë ¹: {ages.mean():.1f}ì„¸")
print(f"ì—°ë ¹ ë²”ìœ„: {ages.min():.0f}ì„¸ - {ages.max():.0f}ì„¸")
print(f"í‘œì¤€í¸ì°¨: {ages.std():.1f}ì„¸")

# íˆìŠ¤í† ê·¸ë¨ ìƒì„±
fig = px.histogram(
    df,
    x='{age_column}',
    nbins=20,
    title='ì—°ë ¹ ë¶„í¬',
    labels={{'{age_column}': 'ì—°ë ¹', 'count': 'ê°œì²´ ìˆ˜'}}
)

fig.update_layout(
    xaxis_title='ì—°ë ¹',
    yaxis_title='ê°œì²´ ìˆ˜',
    height=500
)

chart_json = fig.to_json()
print("\\nğŸ“Š ì—°ë ¹ íˆìŠ¤í† ê·¸ë¨ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")"""

        # ì§€ì—­/ì§€ì—­ë³„ ë¶„ì„
        elif column_mapping.get("analysis_type") == "location_analysis" and column_mapping.get("target_column"):
            location_column = column_mapping["target_column"]
            analysis_type = "location_analysis"
            generated_code = f"""import pandas as pd
import plotly.express as px

# ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„
print("=== ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„ ===")
location_counts = df['{location_column}'].value_counts()
print("ì§€ì—­ë³„ ê°œì²´ ìˆ˜:")
for location, count in location_counts.head(10).items():
    percentage = (count / len(df)) * 100
    print(f"  {location}: {count:,}ë§ˆë¦¬ ({percentage:.1f}%)")

if len(location_counts) > 10:
    print(f"... ë° {len(location_counts) - 10}ê°œ ì§€ì—­ ë”")

# ë°” ì°¨íŠ¸ ìƒì„± (ìƒìœ„ 15ê°œ ì§€ì—­)
top_locations = location_counts.head(15)
fig = px.bar(
    x=top_locations.values,
    y=top_locations.index,
    orientation='h',
    title='ì§€ì—­ë³„ ê°œì²´ ìˆ˜ ë¶„í¬ (ìƒìœ„ 15ê°œ)',
    labels={{'x': 'ê°œì²´ ìˆ˜', 'y': 'ì§€ì—­'}}
)

fig.update_layout(height=600, yaxis_title='ì§€ì—­', xaxis_title='ê°œì²´ ìˆ˜')
chart_json = fig.to_json()
print("\\nğŸ“Š ì§€ì—­ë³„ ë¶„í¬ ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")"""

        # í¬ê¸°/ê¸¸ì´/ë¬´ê²Œ ë¶„ì„
        elif column_mapping.get("analysis_type") == "size_analysis" and column_mapping.get("target_column"):
            size_column = column_mapping["target_column"]
            analysis_type = "size_analysis"
            generated_code = f"""import pandas as pd
import plotly.express as px
import numpy as np

# í¬ê¸° ë¶„í¬ ë¶„ì„
print("=== {size_column} ë¶„í¬ ë¶„ì„ ===")
sizes = df['{size_column}'].dropna()
print(f"í‰ê· : {sizes.mean():.2f}")
print(f"ì¤‘ì•™ê°’: {sizes.median():.2f}")
print(f"ë²”ìœ„: {sizes.min():.2f} - {sizes.max():.2f}")
print(f"í‘œì¤€í¸ì°¨: {sizes.std():.2f}")

# íˆìŠ¤í† ê·¸ë¨ ìƒì„±
fig = px.histogram(
    df,
    x='{size_column}',
    nbins=30,
    title=f'{size_column} ë¶„í¬',
    labels={{'{size_column}': '{size_column}', 'count': 'ê°œì²´ ìˆ˜'}}
)

fig.update_layout(height=500)
chart_json = fig.to_json()
print("\\nğŸ“Š í¬ê¸° ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")"""

        # ì¼ë°˜ì ì¸ ë°ì´í„° ìš”ì•½ (ê¸°ë³¸ê°’)
        else:
            analysis_type = "general_summary"
            generated_code = f"""import pandas as pd
import plotly.express as px

# ë°ì´í„° ì „ì²´ ìš”ì•½
print("=== ë°ì´í„° ìš”ì•½ ===")
print(f"ì´ í–‰ ìˆ˜: {{len(df):,}}")
print(f"ì´ ì»¬ëŸ¼ ìˆ˜: {{len(df.columns)}}")

print("\\nì»¬ëŸ¼ ëª©ë¡:")
for i, col in enumerate(df.columns, 1):
    print(f"  {{i}}. {{col}}")

# ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„
numeric_cols = df.select_dtypes(include=['number']).columns
if len(numeric_cols) > 0:
    print("\\nìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„:")
    for col in numeric_cols[:5]:  # ìµœëŒ€ 5ê°œ
        values = df[col].dropna()
        if len(values) > 0:
            print(f"  {{col}}: í‰ê·  {{values.mean():.2f}}, ë²”ìœ„ {{values.min():.2f}}-{{values.max():.2f}}")

# ì²« ë²ˆì§¸ ë²”ì£¼í˜• ì»¬ëŸ¼ìœ¼ë¡œ ê°„ë‹¨í•œ ì°¨íŠ¸ ìƒì„±
categorical_cols = df.select_dtypes(include=['object']).columns
if len(categorical_cols) > 0:
    chart_col = categorical_cols[0]
    value_counts = df[chart_col].value_counts().head(10)

    fig = px.bar(
        x=value_counts.index,
        y=value_counts.values,
        title=f'{{chart_col}} ë¶„í¬ (ìƒìœ„ 10ê°œ)',
        labels={{'x': chart_col, 'y': 'ê°œìˆ˜'}}
    )

    fig.update_layout(height=500)
    chart_json = fig.to_json()
    print(f"\\nğŸ“Š {{chart_col}} ë¶„í¬ ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
else:
    print("\\nì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ì ì ˆí•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")"""

        # ì½”ë“œê°€ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì½”ë“œ
        if not generated_code:
            generated_code = """print("ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ì½”ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
print("ë°ì´í„°ì˜ ì»¬ëŸ¼ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
for i, col in enumerate(df.columns, 1):
    print(f"  {i}. {col}")"""

        # ìƒì„±ëœ ì½”ë“œë¥¼ ì²­í¬ë¡œ ë¶„í• 
        code_chunks = self._split_code_into_chunks(generated_code)

        # ì‹¤ì œ ë°ì´í„°ë¡œ ì½”ë“œ ì‹¤í–‰
        execution_result = await self._execute_analysis_code_with_data(generated_code, df)

        # ì‹¤í–‰ ê²°ê³¼ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = self._generate_insights_from_results(execution_result, analysis_type, df, question)

        return {
            'output': execution_result.get('output', ''),
            'code_chunks': code_chunks,
            'result': execution_result.get('result', ''),
            'insights': insights,
            'chart_data': execution_result.get('chart_data')
        }

    def _generate_insights_from_results(self, execution_result: Dict[str, Any], analysis_type: str, df: pd.DataFrame, question: str) -> List[str]:
        """ì‹¤í–‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []

        # ê¸°ë³¸ ì‹¤í–‰ ì •ë³´
        if execution_result.get('success', True):
            insights.append(f"âœ… ì´ {len(df):,}í–‰ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")

            execution_time = execution_result.get('execution_time', 0)
            if execution_time > 0:
                insights.append(f"âš¡ ë¶„ì„ ì‹¤í–‰ ì‹œê°„: {execution_time:.3f}ì´ˆ")
        else:
            insights.append("âŒ ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return insights

        # ë¶„ì„ ê²°ê³¼ì—ì„œ ìˆ«ì ì¶”ì¶œ ì‹œë„
        output = execution_result.get('output', '')

        if analysis_type == "gender_analysis":
            insights.append("ğŸ” ì„±ë³„ ë¶„í¬ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì¶œë ¥ì—ì„œ ë¹„ìœ¨ ì •ë³´ ì¶”ì¶œ ì‹œë„
            if '%' in output:
                insights.append("ğŸ“Š ê° ì„±ë³„ì˜ ë¹„ìœ¨ê³¼ ê°œì²´ ìˆ˜ê°€ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.")

            if 'Female' in output or 'Male' in output or 'ì•”ì»·' in output or 'ìˆ˜ì»·' in output:
                insights.append("â™‚â™€ ìˆ˜ì»·ê³¼ ì•”ì»·ì˜ ë¶„í¬ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        elif analysis_type == "age_analysis":
            insights.append("ğŸ“ˆ ì—°ë ¹ ë¶„í¬ í†µê³„ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if 'í‰ê· ' in output:
                insights.append("ğŸ“Š í‰ê·  ì—°ë ¹, ë²”ìœ„, í‘œì¤€í¸ì°¨ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        elif analysis_type == "location_analysis":
            insights.append("ğŸŒ ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            if 'ì§€ì—­' in output:
                insights.append("ğŸ“ ìƒìœ„ ì§€ì—­ë“¤ì˜ ê°œì²´ ìˆ˜ ë¶„í¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        elif analysis_type == "size_analysis":
            insights.append("ğŸ“ í¬ê¸°/ê¸¸ì´ ë¶„í¬ í†µê³„ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if 'í‰ê· ' in output:
                insights.append("ğŸ“Š í‰ê· ê°’, ì¤‘ì•™ê°’, ë²”ìœ„ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        else:
            insights.append("ğŸ“‹ ë°ì´í„° ì „ë°˜ì ì¸ ìš”ì•½ ì •ë³´ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ì°¨íŠ¸ ìƒì„± ì—¬ë¶€ í™•ì¸
        if execution_result.get('chart_data') or 'ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤' in output:
            insights.append("ğŸ“Š ëŒ€í™”í˜• ê·¸ë˜í”„ê°€ ìƒì„±ë˜ì–´ ì‹œê°ì  ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        # ë°ì´í„° í’ˆì§ˆ ê´€ë ¨ ì¸ì‚¬ì´íŠ¸
        if len(df) >= 1000:
            insights.append("ğŸ’ª ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ìœ¼ë¡œ í†µê³„ì ìœ¼ë¡œ ì‹ ë¢°ì„± ìˆëŠ” ë¶„ì„ì…ë‹ˆë‹¤.")
        elif len(df) >= 100:
            insights.append("ğŸ“ˆ ì¶©ë¶„í•œ ìƒ˜í”Œ í¬ê¸°ë¡œ ì˜ë¯¸ìˆëŠ” ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        return insights

    async def _smart_column_mapping(self, question: str, columns: List[str], df: pd.DataFrame) -> Dict[str, str]:
        """AIë¥¼ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ì»¬ëŸ¼ ë§¤í•‘ - ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ ì»¬ëŸ¼ì„ ì°¾ìŒ"""

        # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ (ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ëª‡ ê°œì”©)
        column_info = {}
        for col in columns:
            try:
                unique_values = df[col].dropna().unique()
                if len(unique_values) > 0:
                    # ë„ˆë¬´ ë§ìœ¼ë©´ ì²˜ìŒ 5ê°œë§Œ
                    sample_values = list(unique_values[:5])
                    column_info[col] = {
                        'type': str(df[col].dtype),
                        'sample_values': sample_values,
                        'unique_count': len(unique_values)
                    }
            except:
                column_info[col] = {'type': 'unknown', 'sample_values': [], 'unique_count': 0}

        # AIì—ê²Œ ì»¬ëŸ¼ ë§¤í•‘ ìš”ì²­
        mapping_prompt = f"""
ì‚¬ìš©ìê°€ ë°ì´í„°ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤: "{question}"

ë°ì´í„°ì˜ ì»¬ëŸ¼ ì •ë³´:
{json.dumps(column_info, ensure_ascii=False, indent=2)}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ë‹¤ìŒ ë¶„ì„ ìœ í˜• ì¤‘ í•˜ë‚˜ì™€ í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ì„ ë§¤í•‘í•´ì£¼ì„¸ìš”:

ë¶„ì„ ìœ í˜•:
1. gender_analysis: ì„±ë³„, ìˆ˜ì»·/ì•”ì»·, ë‚¨ë…€ ê´€ë ¨ ë¶„ì„
2. age_analysis: ë‚˜ì´, ì—°ë ¹, ì‚´ ê´€ë ¨ ë¶„ì„
3. location_analysis: ì§€ì—­, ë‚˜ë¼, êµ­ê°€, ìœ„ì¹˜ ê´€ë ¨ ë¶„ì„
4. size_analysis: í¬ê¸°, ê¸¸ì´, ë¬´ê²Œ, í‚¤, ëª¸ë¬´ê²Œ, ì²´ì¤‘, ì¤‘ëŸ‰, í‘œì¤€í¸ì°¨, í‰ê· , ë¶„ì‚° ê´€ë ¨ ë¶„ì„
5. general_summary: ìœ„ì˜ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì¼ë°˜ì ì¸ ë¶„ì„

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "analysis_type": "ë¶„ì„_ìœ í˜•",
  "target_column": "í•´ë‹¹_ì»¬ëŸ¼ëª…_ë˜ëŠ”_null",
  "confidence": 0.8,
  "reasoning": "ì„ íƒí•œ ì´ìœ "
}}

ì£¼ì˜ì‚¬í•­:
- í•œêµ­ì–´ ì§ˆë¬¸ì´ì–´ë„ ì˜ì–´ ì»¬ëŸ¼ëª…ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ë§¤ì¹­í•´ì£¼ì„¸ìš”
- ìƒ˜í”Œ ê°’ì„ ë³´ê³  ì»¬ëŸ¼ì˜ ì‹¤ì œ ë‚´ìš©ì„ íŒë‹¨í•˜ì„¸ìš”
- í™•ì‹ ì´ ì—†ìœ¼ë©´ confidenceë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ ì»¬ëŸ¼ì„ ë§¤í•‘í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": mapping_prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )

            mapping_result = response.choices[0].message.content.strip()

            # JSON íŒŒì‹± ì‹œë„

            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', mapping_result, re.DOTALL)
            if json_match:
                mapping_data = json.loads(json_match.group())
                return mapping_data
            else:
                return {"analysis_type": "general_summary", "target_column": None, "confidence": 0.0, "reasoning": "JSON íŒŒì‹± ì‹¤íŒ¨"}

        except Exception as e:
            print(f"Smart column mapping error: {e}")
            return {"analysis_type": "general_summary", "target_column": None, "confidence": 0.0, "reasoning": f"ì˜¤ë¥˜: {str(e)}"}

    def _enhance_question_with_context(self, question: str, conversation_history: list = None) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì„ ë§¥ë½ì ìœ¼ë¡œ ê°•í™”"""
        if not conversation_history or len(conversation_history) == 0:
            return question

        # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ì‚¬ìš© (í† í° í•œë„ ê³ ë ¤)
        recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history

        # ì°¸ì¡° ë‹¨ì–´ë“¤ ì²´í¬ ("ì´ê²ƒ", "ê·¸ê²ƒ", "ì´ ë°ì´í„°", "ìœ„ì˜ ê²°ê³¼" ë“±)
        reference_words = [
            "ì´ê²ƒ", "ê·¸ê²ƒ", "ì´ê±°", "ê·¸ê±°", "ì´", "ê·¸",
            "ì´ ë°ì´í„°", "ì´ íŒŒì¼", "ì´ ê²°ê³¼", "ìœ„ì˜", "ì•ì„œ",
            "ë°©ê¸ˆ", "ì§ì „", "ì´ì „", "ë‹¤ì‹œ", "ë˜", "ì¶”ê°€ë¡œ",
            "it", "this", "that", "these", "those", "above", "previous"
        ]

        has_reference = any(word in question.lower() for word in reference_words)

        if not has_reference:
            # ì°¸ì¡° ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ì›ë˜ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return question

        # ì°¸ì¡° ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ëŒ€í™” ë§¥ë½ì„ í¬í•¨í•œ ê°•í™”ëœ ì§ˆë¬¸ ìƒì„±
        context_summary = ""

        # ìµœê·¼ ëŒ€í™”ì—ì„œ íŒŒì¼/ë°ì´í„° ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        data_context = []
        for msg in recent_history:
            if msg.get('role') == 'assistant':
                content = msg.get('content', '')
                # ë°ì´í„° ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
                if any(keyword in content.lower() for keyword in ['ë°ì´í„°', 'íŒŒì¼', 'ë¶„ì„', 'ê·¸ë˜í”„', 'ì°¨íŠ¸', 'í‰ê· ', 'ê°œì²´', 'ì»¬ëŸ¼']):
                    # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ (ì²« 50ì)
                    summary = content[:100] + "..." if len(content) > 100 else content
                    data_context.append(summary)

        if data_context:
            context_summary = f"ì´ì „ ë¶„ì„ ë‚´ìš©: {'; '.join(data_context[-2:])}\n\n"  # ìµœê·¼ 2ê°œë§Œ

        enhanced_question = f"{context_summary}ì‚¬ìš©ì ì§ˆë¬¸: {question}"

        print(f"ğŸ“ Context enhancement applied - Reference words found: {has_reference}")
        return enhanced_question

    async def _generate_flexible_analysis_code(self, question: str, df: pd.DataFrame, column_info: dict) -> str:
        """AIê°€ ì§ì ‘ Python ë¶„ì„ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ìœ ì—°í•œ ì‹œìŠ¤í…œ"""

        # ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
        data_summary = f"""
ë°ì´í„°ì…‹ ì •ë³´:
- ì´ í–‰ ìˆ˜: {len(df):,}
- ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}
- ì»¬ëŸ¼ ì •ë³´: {json.dumps(column_info, ensure_ascii=False, indent=2)}

ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):
{df.head(3).to_dict('records')}
"""

        analysis_prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{question}"

{data_summary}

ìœ„ ë°ì´í„°ì— ëŒ€í•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ëŠ” Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:
1. import pandas as pd, import plotly.express as px í¬í•¨
2. ë°ì´í„°ëŠ” ì´ë¯¸ 'df' ë³€ìˆ˜ë¡œ ë¡œë“œë˜ì–´ ìˆìŒ
3. ì§ˆë¬¸ì— ë§ëŠ” ì ì ˆí•œ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì„ íƒ
4. ë¶„ì„ ê²°ê³¼ë¥¼ ëª…í™•í•˜ê²Œ printë¡œ ì¶œë ¥
5. ê°€ëŠ¥í•˜ë©´ ì‹œê°í™”(plotly) í¬í•¨í•˜ê³  chart_json = fig.to_json() ë¡œ ì €ì¥
6. í•œêµ­ì–´ë¡œ ì¶œë ¥ ë©”ì‹œì§€ ì‘ì„±
7. ì»¬ëŸ¼ëª…ì´ ì˜ì–´ì—¬ë„ ì˜ë¯¸ë¥¼ íŒŒì•…í•´ì„œ ë¶„ì„

ë¶„ì„ íƒ€ì… ì˜ˆì‹œ:
- ì„±ë³„/gender ë¶„í¬: ë§‰ëŒ€ ì°¨íŠ¸
- ì—°ë ¹/age ë¶„í¬: íˆìŠ¤í† ê·¸ë¨
- ì§€ì—­/location ë¶„í¬: ë§‰ëŒ€ ì°¨íŠ¸
- ìˆ˜ì¹˜ í†µê³„: í‰ê· , í‘œì¤€í¸ì°¨, íˆìŠ¤í† ê·¸ë¨
- ìƒê´€ê´€ê³„: scatter plot
- ì‹œê³„ì—´: line plot

ì½”ë“œë§Œ ë°˜í™˜í•˜ê³  ì„¤ëª…ì€ ìƒëµí•˜ì„¸ìš”.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ëŠ” ì •í™•í•œ Python ë¶„ì„ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.1,
                max_tokens=2000
            )

            generated_code = response.choices[0].message.content.strip()

            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if '```python' in generated_code:
                generated_code = generated_code.split('```python')[1].split('```')[0]
            elif '```' in generated_code:
                generated_code = generated_code.split('```')[1].split('```')[0]

            generated_code = generated_code.strip()

            print(f"ğŸ¤– AI generated flexible analysis code:")
            print(f"Code preview: {generated_code[:200]}...")

            return generated_code

        except Exception as e:
            print(f"AI code generation error: {e}")
            # í´ë°±: ê¸°ë³¸ ë°ì´í„° ìš”ì•½ ì½”ë“œ
            return f"""import pandas as pd
import plotly.express as px

print("=== ë°ì´í„° ë¶„ì„ ===")
print(f"ì´ {len(df):,}ê°œ í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
print("\\nê¸°ë³¸ í†µê³„:")
print(df.describe())

print("\\nğŸ“Š ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")"""

    async def _generate_general_analysis_code(self, question: str) -> Dict[str, Any]:
        """íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ì¼ë°˜ì ì¸ ë¶„ì„ ì½”ë“œ ìƒì„±"""

        # ì§ˆë¬¸ì—ì„œ ìˆ«ìì™€ ì—°ì‚°ì ì¶”ì¶œ
        import re

        # ìˆ˜ì‹ íŒ¨í„´ ê°ì§€
        math_expression_pattern = r'[\d+\-*\/\(\)\.\s]+'
        has_math_expression = bool(re.search(r'[\d\s]*[\+\-\*\/][\d\s]*', question))

        if has_math_expression:
            # ìˆ˜ì‹ì´ ìˆëŠ” ê²½ìš°, ì „ì²´ ìˆ˜ì‹ì„ ì¶”ì¶œ
            expression_match = re.search(r'[0-9+\-*\/\(\)\.\s]+', question)
            math_expression = expression_match.group(0).strip() if expression_match else None
        else:
            # ë‹¨ìˆœ ìˆ«ì ëª©ë¡ì¸ ê²½ìš°
            math_expression = None

        numbers = re.findall(r'\d+(?:\.\d+)?', question)

        if math_expression:
            # ìˆ˜ì‹ì—ì„œ ì˜ëª»ëœ ì—°ì‚°ì íŒ¨í„´ ìˆ˜ì •
            clean_expression = math_expression.replace('+*', '*').replace('-*', '*').replace('**', '*')
            # ë” í™•ì‹¤í•œ ì½”ë“œ ìƒì„±ì„ ìœ„í•´ ì§ì ‘ êµ¬ì„±
            direct_code = f'result = eval("{clean_expression}")\nprint(f"ê²°ê³¼: {{result}}")'

            code_prompt = f"""You must return exactly this Python code with NO changes, NO additions, NO markdown:

{direct_code}

Return ONLY the above code. Nothing else."""
        else:
            # ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            int_numbers = [int(num) for num in numbers if num.isdigit()]
            direct_code = f'data = {int_numbers}\nresult = sum(data)\nprint(f"ì´í•©: {{result:,}}")'

            code_prompt = f"""You must return exactly this Python code with NO changes, NO additions, NO markdown:

{direct_code}

Return ONLY the above code. Nothing else."""

        # AIì— ì˜ì¡´í•˜ì§€ ì•Šê³  ì§ì ‘ ì½”ë“œ ìƒì„± (ë” ì•ˆì •ì )
        if math_expression:
            generated_code = f'result = eval("{clean_expression}")\nprint(f"ê²°ê³¼: {{result}}")'
        else:
            # ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            int_numbers = [int(num) for num in numbers if num.isdigit()]
            generated_code = f'data = {int_numbers}\nresult = sum(data)\nprint(f"ì´í•©: {{result:,}}")'

        print(f"ì§ì ‘ ìƒì„±ëœ ì½”ë“œ:\n{generated_code}")

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ê³¼ ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°
        def clean_code(code_text: str) -> str:
            """AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ì—ì„œ ìˆœìˆ˜ Python ì½”ë“œë§Œ ì¶”ì¶œ"""
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (ë” ê°•ë ¥í•œ ì œê±°)
            if '```python' in code_text:
                code_text = code_text.split('```python')[1].split('```')[0]
            elif '```' in code_text:
                parts = code_text.split('```')
                if len(parts) >= 3:
                    code_text = parts[1]

            # ë¶ˆí•„ìš”í•œ ì„¤ëª… í…ìŠ¤íŠ¸ ì™„ì „ ì œê±°
            if 'CRITICAL:' in code_text:
                parts = code_text.split('CRITICAL:')[0].strip()
                if parts:
                    code_text = parts

            if 'Required format:' in code_text:
                parts = code_text.split('Required format:')[1].strip()
                if parts:
                    code_text = parts

            lines = code_text.split('\n')
            code_lines = []

            # ì¤‘ë³µëœ print ë¬¸ ë°©ì§€ë¥¼ ìœ„í•œ ì„¸íŠ¸
            seen_prints = set()

            for line in lines:
                stripped = line.strip()

                # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                if not stripped:
                    continue

                # ì„¤ëª…ì„± í…ìŠ¤íŠ¸ ì™„ì „ ì œê±°
                if (not any(c in stripped for c in ['=', '(', '[']) and
                    any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in stripped)):
                    continue

                # Python ì½”ë“œê°€ ì•„ë‹Œ ê²ƒë“¤ ì œê±°
                if (stripped.startswith('Task:') or
                    stripped.startswith('Numbers:') or
                    stripped.startswith('Calculate') or
                    stripped.startswith('CRITICAL:') or
                    stripped.startswith('Required format:')):
                    continue

                # ì¤‘ë³µëœ print ë¬¸ ì œê±°
                if stripped.startswith('print('):
                    if stripped in seen_prints:
                        continue
                    seen_prints.add(stripped)

                # ìœ íš¨í•œ Python ì½”ë“œë§Œ ì¶”ê°€
                if (('=' in stripped) or
                    stripped.startswith('print(') or
                    stripped.startswith('result') or
                    stripped.startswith('data') or
                    ('    ' in line and line.strip())):  # ë“¤ì—¬ì“°ê¸°ëœ ë¼ì¸
                    code_lines.append(line.rstrip())

            return '\n'.join(code_lines)

        # ì›ë³¸ ì½”ë“œ ë³´ê´€ (ë””ë²„ê¹…ìš©)
        original_code = generated_code
        generated_code = clean_code(generated_code)

        # ì •ì œëœ ì½”ë“œë¥¼ ì²­í¬ë¡œ ë¶„í• 
        code_chunks = self._split_code_into_chunks(generated_code)

        # ì½”ë“œ ì‹¤í–‰
        execution_result = await self._execute_analysis_code(generated_code, pd.DataFrame())

        # ê²°ê³¼ í¬ë§·íŒ…
        return {
            'output': execution_result.get('output', ''),
            'code_chunks': code_chunks,
            'result': execution_result.get('result', ''),
            'insights': [
                "âœ… ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            ],
            'success': execution_result.get('success', False)
        }

    async def _execute_analysis_code_with_data(self, code: str, df: pd.DataFrame) -> Dict[str, Any]:
        """ì‹¤ì œ ë°ì´í„°ì™€ í•¨ê»˜ ë¶„ì„ ì½”ë“œ ì‹¤í–‰"""
        try:
            # ì½”ë“œ ì‹¤í–‰ API í˜¸ì¶œ
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "http://localhost:8000/api/code/execute",
                    json={
                        "code": code,
                        "context": {
                            "df": df.to_dict('list'),  # list í˜•íƒœë¡œ ì§ë ¬í™”
                            "data": df.to_dict('list'),
                            "rows": len(df),
                            "columns": df.columns.tolist()
                        }
                    },
                    timeout=30.0
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    return {
                        "success": False,
                        "output": "",
                        "error": f"ì‹¤í–‰ ì‹¤íŒ¨: {response.status_code}",
                        "execution_time": 0
                    }

        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                "execution_time": 0
            }

    async def _generate_follow_up_questions(self, original_question: str, analysis_result: Dict[str, Any]) -> List[str]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ ì§ˆë¬¸ ìƒì„±"""
        try:
            follow_up_prompt = f"""
ì‚¬ìš©ìê°€ "{original_question}"ë¼ê³  ì§ˆë¬¸í–ˆê³ , ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤:

ê²°ê³¼: {analysis_result.get('output', '')[:500]}...

ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì¶”ê°€ë¡œ ê¶ê¸ˆí•´í•  ë§Œí•œ ê´€ë ¨ ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. í˜„ì¬ ë¶„ì„ì„ ì‹¬í™”ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì§ˆë¬¸
2. ë‹¤ë¥¸ ê´€ì ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸
3. ì‹¤ë¬´ì ìœ¼ë¡œ ìœ ìš©í•œ ì§ˆë¬¸
4. ê° ì§ˆë¬¸ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
5. ì§ˆë¬¸ë§Œ ë°˜í™˜ (ë²ˆí˜¸ë‚˜ ì„¤ëª… ì—†ì´)

ì˜ˆì‹œ:
ì´ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ëŠ” ì–´ë–»ê²Œ ë¶„í¬ë˜ì–´ ìˆë‚˜ìš”?
ì‹œê°„ëŒ€ë³„ íŠ¸ë Œë“œëŠ” ì–´ë–»ê²Œ ë³€í™”í•˜ê³  ìˆë‚˜ìš”?
ë‹¤ë¥¸ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
"""

            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë°ì´í„° ë¶„ì„ ê´€ë ¨ í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": follow_up_prompt}
                ],
                temperature=0.7,
                max_tokens=200
            )

            questions_text = response.choices[0].message.content.strip()
            questions = [q.strip() for q in questions_text.split('\n') if q.strip()]

            return questions[:3]  # ìµœëŒ€ 3ê°œë§Œ ë°˜í™˜

        except Exception as e:
            print(f"Follow-up questions generation error: {str(e)}")
            return [
                "ì´ ê²°ê³¼ë¥¼ ë‹¤ë¥¸ ê´€ì ì—ì„œ ë¶„ì„í•´ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?",
                "ì¶”ê°€ì ìœ¼ë¡œ í™•ì¸í•´ë³¼ ë§Œí•œ íŒ¨í„´ì´ ìˆì„ê¹Œìš”?",
                "ì´ ë°ì´í„°ì˜ ë‹¤ë¥¸ íŠ¹ì„±ì€ ì–´ë–»ê²Œ ë ê¹Œìš”?"
            ]